\chapter{Architektur}\label{ch:method}

\section{Mikrosystemarchitektur}

Der zweite Teil des Systems besteht darin, aus der Anfrage der Nutzenden eine passende Podcastepisode zu erstellen.
Die dazu notwendigen Schritte lassen sich zunächst in mehrere kleinen Projekte unterteilen. 
Bei einem so großen Projekt lohnt es sich eine Mikroservice Architektur anzustreben, bei der jeder Teil für sich gesehen eine Aufgabe erfüllt und die einzelnen Systeme nur über festgelegte Programmierschnittstellen (APIs) miteinander kommunizieren.
Diese Methode wird auch divide-and-conquer genannt. 

Um das Projekt weiter einzuordnen, bietet es sich an, vorab Anforderungen an das System zu stellen. 
Da das gesamte Projekt als eine Reihe von Mikroservices umgesetzt werden soll, werden folgend für jeden Mikroservice einzelne Anforderungen gestellt: 

\section{Anforderungen}

Zunächst muss die Datengrundlage geschafft werden. 
Dafür müssen die Podcast Episoden heruntergeladen, transkribiert und anschließend alle Sätze in der Datenbank abgespeichert werden.
Dieses System muss in der Lage dem Titel eines Podcasts bzw. der ID in der Audiothek, sämtliche noch nicht in der Datenbank gespeicherten Episoden herunterzuladen, zu transkribieren und abzuspeichern.
In der Zukunft könnte man darüber nachdenken, diesen Teil komplett auf der Serverseite der ARD Audiothek laufen zu lassen.

Das nächste Mikrosystem muss in der Lage sein, diese Transkriptdaten in eine Form umzuwandeln, in der eine Suchfunktion relevante Abschnitte aus diesen Daten extrahieren kann.
Dafür soll es die einzelnen Wörter in sinnvolle Abschnitte Gruppieren und ein Embedding für jeden Abschnitt berechnen.

Ein weiterer Service soll dann die Suchfunktion übernehmen, indem er Stichworte oder Sätze als Parameter erhält und zu diesen die eine bestimmte Anzahl an relevanten Abschnitten zurückgibt.

Diese relevanten Abschnitte können noch weiter von ChatGPT analysiert werden, um zum Beispiel eine Auswahl aus vielen Dokumenten zu treffen, die Reihenfolge der Abschnitte zu bestimmen, oder ähnliche Themen herauszufinden.

Der nächste Service muss in der Lage sein, eine Liste an Segmenten entgegenzunehmen und daraus eine Audiodatei zu erzeugen.
Dafür muss er die Originaldatein an den richtigen Stellen schneiden und die Audioschnipsel zusammenfügen können.

Als Letztes muss die Audiodatei ausgeliefert werden. 
Dafür soll einmal eine API implementiert werden.
Außerdem soll ein UI als Webseite aufgebaut werden, welche die Anfrage in einem Formular entgegennimmt und dann die Audiodatei ausliefert.


\section{Programmiersprache Python}

In dieser Arbeit wird die Programmiersprache Python verwendet.
Python zählt zu den am meißten verwendeten Programmiersprachen weltweit und ist laut dem TIOBE-Index im Jahr 2023 sogar die meist verwendete Programmiersprache überhaupt \cite{index2023}.
In dieser Arbeit wird Python verwendet, da es Unterstützung für sehr gute Bibliotheken für Machine Learning und NLP Anwendungen gibt.
Vor allem die Unterstützung für Transformermodelle mit der Bibliothek transformers, die NLP Bibliothek SpaCy, sowie Datenverwaltungsbibliotheken wie pandas und support für SQLite Datenbanken mit sqlite sind sehr praktisch.
Dazu ist Python sehr einfach zu verstehen und rechenaufwändige Operationen wie in der transformers-Bibliothek sind sehr performant in der Sprache C implementiert.


\section{Transktript Segment Ranking}



\subsection{Embeddings Dense}

Dazu werden die einzelnen Segmente mit den verschiedenen Modellen embedded.
Am Anfang des Segments kann noch einmal der Titel der Episode angefügt werden, was eventuell die Performance steigert.\cite{jones2021}






\subsection{Anreicherung der Segmente}

Das Ranking der einzelnen Sätze liefert eine Auswahl der besten Kandidaten für den Podcast.
Einzelne Sätze, die aus verschiedenen Podcast Episoden stammen, ohne Kontext hintereinander abzuspielen bietet für den Zuhörer nur ein mäßiges Hörerlebnis. 
Es fehlt der Kontext zu den einzelnen Informationen.
Zum Besipiel bekommt man für die Suchanfrage "Geschichte Amsterdam" mit dem TF-IDF Ansatz Sätze wie "Amsterdam, das bedeutet unbeschwerte Kinderjahre" oder "Amsterdam gefiel ihm".
Die Sätze an sich bieten kaum interessante Informationen.
Dem Zuhörer stellen sich sogar noch mehr Fragen, zum Beispiel für wen Amsterdam unbeschwerte Kinderjahre bedeuten oder wem Amsterdam gefiel.

Um dem Zuhörer mehr Informationen zu geben, kann man die Größe der einzelnen Segmente Anpassen.
Dazu kann man mehrere Ansätze betrachten.
Der einfachste Ansatz ist, für jeden einzelnen Satz die umgebenden Sätze davor und dahinter miteinzubeziehen.
Die Anzahl der umgebenden Sätze ist dann ein Hyperparameter dieses Systems und kann vom Nutzer durch den Parameter Segmentlänge eingestellt werden, welher die Anzahl der Sätze in einem Segment angibt.
Falls der auszuschneidende Satz am Anfang oder am Ende des Transkriptes vorkommt, und die Segmentlänge so eingestellt ist, dass mehr Sätze als möglich dem Segment hinzugefügt werden sollten, so wird das Segment an der Transkriptgrenze abgeschnitten.
Die Evaluation der besten Segmentlänge wurde in dieser Arbeit nicht ausgeführt, als defaultwert ist für die Segmentlänge 5 eingestellt.

Ein weiterer Ansatz wäre auch hier ein mächtiges LLM, wie ChatGPT zu benutzen, um die richtige Segmentlänge für jedes Segment individuell einzustellen.
Dazu kann man das LLM instruieren, aus einer sehr großen Anzahl an Kontextsätzen (zum Beispiel 50) oder dem ganzen Transkript einer Podcast Episode und der dazugehörigen Frage, die Anzahl der Kontextsätze auf das wesentliche zu beschränken.


In dieser Arbeit wurde dieser Ansatz ausprobiert mithilfe eines Promptes wie 

Je nachdem welches LLM man dafür benutzt könnten Zeit und kostenfaktoren eine Rolle spielen.


\subsection{Reranking mit ChatGPT}

Nachdem nun die einzelnen Sätze zu gößeren Segmenten erweitert wurden, kann man auch die Reihenfolge der einzelnen Segmente anpassen.
Wenn man sich beispielsweise über die "Geschichte von Amsterdam" informieren will, kommen dazu verschiedene Ausschnitte aus der Zeit der Gründung der Niederlande in 1581, den Besuchen Peter des Großen in Amsterdam im Jahr 1697 oder der Verfolgung der Juden im Zweiten Weltkrieg.
Die Reihenfolge dieser Ereignisse wird im Retrival Schritt dadurch bestimmt, wie stark die Ähnlichkeit zwischen diesem Segent und der Frage ist.
In diesem Fall wäre es sehr nützlich die Reihenfolge so umzuändern, dass die Segmente zeitlich sortiert wären.
In anderen Fällen könnte es Sinnvoll sein, dass Segmente hintereinander erscheinen, die einen Inhaltlichen Zusammenhang besitzen.
Zum Beispiel würde zu dem Thema "Mauerfall Berlin" mehrere Segmente vorkommen, die sich auch mit der DDR befassen.
In diesem Fall währe es für Zuhörende spannend diese Segmente hintereinander zu platzieren, um dem Podcast flüssiger und zusammenhängender zu gestalten.

Ein solches Reranking der einzelnen Segmente kann mithilfe von leistungsstarken LLMs wie ChatGPT erreicht werden.
Dazu werden die einzelnen Segmente nummeriert an die Inferenz API von ChatGPT geschickt und das LLM soll die neue Reihenfolge als Liste zurückgeben.
Dafür wird der JSON Modus von ChatGPT genutzt, welcher das LLM dazu bringt, die Antwort als JSON String zurückzugeben.
Ein Beispielprompt kann im Anhang nachgelesen werden \autoref{ch:chatgpt-reranking}.

Da dies eine relativ einfache Aufgabe ist, in der nur eine Liste mit wenigen Zahlen zurückgegeben werden muss, wird in diesem Schritt auf Techniken des Prompt engineerings verzichtet.

\section{Audio-Zusammensetzung}


Für die Bearbeitung von Audio files in Python bietet sich das Python-Modul Pydub an. 
Mit diesem Modul kann ein Audiofile ähnlich wie ein Array behandelt werden.
Wenn sich zum Beispiel in einem Audiofile ein wichtiges Segment von Sekunde 34 bis Sekunde 64 erstreckt,  kann dort einfach die Start- und Endzeit in Arrayschreibweise angegeben werden.
Im Hintergrund verwendet dieses Modul Software-Bibliotheken des Softwareprojekts FFmpeg, welche umfangreichen Support für die Bearbeitung fast aller Audioformate besitzt.\cite{ffmpeg}
Für die Zeitstempel der Start und End Zeit jedes Audiosegments nehmen wir die Daten aus den vorher aus der SQLite extrahierten relevanten Segmenten.
Diese werden dann als extra Audiofiles als WAV Datein in einem seperaten Ordner abgespeichert, um einem Qualitätsverlust durch die Codierung des verlustbehafteten Codierungsformat MP3 vorzubeugen.

Um die Audios nun wieder zusammenzusetzen, verwenden wir das gleiche Modul Pydub. 
Es bieten sich mehrere Möglichkeiten an, die Audiosegmente zusammenzusetzen. 
Der primitivste Ansatz wäre, die Segmente einfach ohne Pause hintereinander abspielen. 
Die einzelnen Segmente beginnen und enden meist abrubt und das hintereinanderschalten mehrerer Segmente ohne Pause führt zu verwirrungen, wo ein Segment endet und wo das nächste anfängt.
Dafür bietet sich ein kurzer Signalton zwischen den einzelnen Audiosegmenten an. 
Dieser sollte nicht nervig sein, da er dem Hörer öfter vorgespielt wird. 
In dieser Arbeit wurde ein kleiner Jingle, der zum Anfang einer Episode abgespielt wird als Signalton verwendet.

Eine weitere Möglichkeit wäre, zwischen jedem Segment dem Hörer eine kurze Vorstellung der Episode und der Sprecher*in zu ermöglichen oder sogar Kontext zu dieser zu geben. 
Dazu könnte eine kurze Einleitung zu jedem Segment mit einer synthetisch generierten Stimme erstellt werden.
Dieser Ansatz wurde hier aber nicht weiter verfolgt.

\section{Weiterführende Themenvorschläge}

Um den Zuhörenden die Möglichkeit zu geben, auf verschiedene Themen, die im Podcast erwähnt wurden, weiter einzugehen, wurden entsprechende Themenvorschläge mithilfe von ChatGPT generiert.
Wenn zum Beispiel in einem Podcast zur "Geschichte von Amsterdam" einzelne Segmente über die Anfangszeit der Niederlande handeln, könnte man sich in einer weiterführenen Episode zum Beispiel über die "Gründung der Niederlande" informieren.
Zu diesem Zweck werden für jede generierte Podcastepisode fünf weiterführende Themenvorschläge von ChatGPT generiert, die zu den Segmenten passen.
Dazu wird wieder ChatGPT3.5 im JSON Modus verwendet.
Ein Beispielprompt ist hier zu lesen \autoref{ch:chatgpt-reranking}.
Die Themen werden explizit auf 1-3 Wörter beschränkt, da sonst manchmal ganze Sätze als Themenvorschläge geführt werden, wie zum Beispiel "Die Erfahrungen von Juden in Amsterdam während der Nazibesetzung".
Die Antwort von ChatGPT besteht aus einem JSON Array, welches die weiteführenden Themen enthält.
Die einzelnen Themen können je nach Auslieferungsart des Systems zum Beispiel als Buttons angezeigt werden, die eine erneute Suche auslösen, sobald ein nutzende Person ihn drückt.

\section{Auslieferung}

Das System wird in diesem Prototyp als Webservice zur Nutzung angeboten. 
Für das Deployment dieses Tools wurde das Webframework Flask genutzt.
Flask ist ein Web Service Gateway Interface Server (WSGI), welches das Bereitstellen von Webseiten über die WSGI Schnittstelle ermöglicht, welche dann von einem HTTP Server ausgeliefert werden können.
In dieser Arbeit wird dafür der WSGI HTTP Server gunicorn verwendet.
Gunicorn ist für Unix Systeme geeignet, einfach zu konfigurieren und bietet support für mehrere Worker, die mehrere Anfragen gleichzeitig bearbeiten können.

Für die Auslieferung wurde eine API und eine Webseite entwickelt.

\subsection{API}

Über die API kann der Podcast Generator einfach von anderen Anwendungen aufgerufen werden.
Die API wird aufgerufen über eine GET Request auf die unterseite /api .

Als Parameter akzeptiert die API einen String "text", welcher die Frage des Nutzers angibt.
Außerdem kann über den Parameter "time" ein Integerwert angegeben werden, welcher die Zeit des Podcasts in Minuten angibt.
Der optionale Parameter "segment-length" kann als Integer übergeben werden und bestimmt die Länge der einzelnen Segmente.

Die API gibt bei erfolgreicher Verarbeitung den Statuscode 200 zurück und liefert als Inhalt ein JSON String zurück der eine einzige Variable "url" enthält.
Diese URL verweist auf das generierte MP3 file, das ab diesem Zeitpunkt unter der Adresse /static/audios verfügbar ist.

Als Demonstration wurde außerdem ein Telegram-Bot entwickelt der die API benutzt, um damit die automatische Podcastepisoden zu erstellen.
Der Telegram-Bot ist öffentlich verfügbar und kann über die Adresse https://t.me/PodcastGenerator gefunden werden.

\subsection{Design Webseite}

Die Webseite des Podcast Generators bieten einen einfachen Weg das System zu benutzen.
Es gibt die beiden Input Felder Thema und Zeit, und einen Start Button, bei dem die Generierung der Podcasts startet.
Nachdem die Podcastepisode fertig generiert wurde, wird der vorher ausgegraute Audioplayer aktiv.
Dann können Nutzende die Audiodatei mithilfe des Players anhören.
Außerdem ist unter/neben dem Audioplayer eine Box mit den Transkriptabschnitten des Podcasts, sortiert nach der Erscheinung in der generierten Episode.
Diese Transkriptabschnitte können zur Navigation innerhalb der Podcastepisode verwendet werden.


Das Design der Webseite beruht auf einem Template von https://github.com/muhammed/mini-player.
Dieses Template wurde erweitert, durch einen Suchbereich und einen Transkript Bereich.




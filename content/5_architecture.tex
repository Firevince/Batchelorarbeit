\chapter{Architektur}\label{ch:method}

\section{Mikrosystemarchitektur}

Der zweite Teil des Systems besteht darin, aus der Anfrage der Nutzenden eine passende Podcastepisode zu erstellen.
Die dazu notwendigen Schritte lassen sich zunächst in mehrere kleinen Projekte unterteilen. 
Bei einem so großen Projekt lohnt es sich eine Mikroservice Architektur anzustreben, bei der jeder Teil für sich gesehen eine Aufgabe erfüllt und die einzelnen Systeme nur über festgelegte Programmierschnittstellen (APIs) miteinander kommunizieren.
Diese Methode wird auch divide-and-conquer genannt. 

Um das Projekt weiter einzuordnen, bietet es sich an, vorab Anforderungen an das System zu stellen. 
Da das gesamte Projekt als eine Reihe von Mikroservices umgesetzt werden soll, werden folgend für jeden Mikroservice einzelne Anforderungen gestellt: 

\section{Anforderungen}

Zunächst muss die Datengrundlage geschafft werden. 
Dafür müssen die Podcast Epsioden heruntergeladen, transkribiert und anschließend alle Sätze in der Datenbank abgespeichert werden.
Dieses System muss in der Lage dem Titel eines Podcasts bzw. der ID in der Audiothek, sämtliche noch nicht in der Datenbank gespeicherten Episoden herunterzuladen, zu transkribieren und abzuspeichern.
In der Zukunft könnte man darüber nachdenken, diesen Teil komplett auf der Serverseite der ARD Audiothek laufen zu lassen.

Das nächste Mikrosystem muss in der Lage sein, diese Transkriptdaten in eine Form umzuwandeln, in der eine Suchfunktion relevante Abschnitte aus diesen Daten extrahieren kann.
Dafür soll es die einzelnen Wörter in sinnvolle Abschnitte Gruppieren und ein Embedding für jeden Abschnitt berechnen.

Ein weiterer Service soll dann die Suchfunktion übernehmen, indem er Stichworte oder Sätze als Parameter erhält und zu diesen die eine bestimmte Anszahl an relevanten Abschnitten zurückgibt.

Diese relevanten Abschnitte können noch weiter von ChatGPT analysiert werden, um zum Besipiel eine Auswahl aus vielen Dokumenten zu treffen, die Reihenfolge der Abschnitte zu bestimmen, oder ähnliche Themen herauszufinden.

Der nächste Service muss in der Lage sein, eine Liste an Segmenten entgegenzunehmen und daraus eine Audiodatei zu erzeugen.
Dafür muss er die originaldatein an den richtigen Stellen schneiden und die Audioschnipsel zusammenfügen können.

Als letztes muss die Audiodatei ausgeliefert werden. 
Dafür soll einmal eine API implementiert werden.
Außerdem soll ein UI als Webseite aufgbaut werden, welche die Anfrage in einem Formular entgegennimmt und dann die Audiodatei ausliefert.


\section{Vorgehensweise}


Zunächst müssen die Daten gesammelt und aufbereitet werden. 
Für dieses Projekt bildet die Datengrundlage die Transkripte, bzw. Manuskripte der Podcasts der ARD-Audiothek. 
In der Audiothek selber gibt es keine Transkripte zu den Podcasts. 
Für den Podcast „radiowissen“ von bayern2 gibt es auf deren Seite die Manuskripte in PDF Format. 
Diese sind zwar inhaltlich hochqualitativ, da Sie exakte Wortwahl der Podcasts enthalten, als PDF Format sind sie allerdings schwierig maschinell auszulesen und weiterhin besitzen sie keine Zeitinformationen zu den einzelnen Wörtern. 
Die Zeitinformationen in Form von Zeitstempeln für jedes Wort sind wichtig, um die Audiofiles der Podcasts später an den richtigen Stellen zuzuschneiden. 

Ein anderer Ansatz ergibt sich, wenn man die Podcasts transkribiert. 
Die Vorteile sind, dass die Transkription auch bei Podcasts funktioniert, für die vorab kein Transkript erstellt wurde, was die Mehrzahl aller Podcasts ausmacht. 
Außerdem kann man bei einer Transkription auch gleichzeitig die Zeitstempel für jedes Wort extrahieren.



\section{Programmiersprache Python}

In dieser Arbeit wird die Programmiersprache Python verwendet.
Python zählt zu den am meißten verwendeten Programmiersprachen weltweit und ist laut dem TIOBE-Index im Jahr 2023 sogar die meißt verwendete Programmiersprache überhaupt \cite{index2023}.
In dieser Arbeit wird Python verwendet, da es Unterstützung für sehr gute Bibliotheken für Machine Learning und NLP Anwendungen gibt.
Vor allem die Unterstützung für Transformermodelle mit der Bibliothek transformers, die NLP Bibliothek SpaCy, sowie Datenverwaltungsbibliotheken wie pandas und support für SQLite Datenbanken mit sqlite sind sehr praktisch.
Dazu ist Python sehr einfach zu verstehen und rechenaufwändige Operationen wie in der transformers Bibliothek sind sehr performant in der Sprache C implementiert.


\section{Transktript Segment Ranking}


\subsection{Ähnlichkeitsvergleiche}

Mithilfe der Embedding Vektoren können können wir Sätze finden, die zueinander Ähnlich sind. Aber was bedeutet überhaupt ähnlich? Die Vektoren des BERT Models sind 768 Dimensional, haben also 768 Gleitkommazahlen gespeichert, die zwischen -1 und 1 liegen. 
Diese Gleitkommazahlen Vektoren könnte man auch als Feature Vektoren begreifen. 
Zum Beispiel könnte die erste Zahl dieses Vektors für die Erwähnung von Professoren in dem Satz stehen (-1 für keine Professoren; 1 für viele Professoren). 
Die zweite Zahl könnte für das Thema Essen stehen (-1 für wenig mit Essen zu tun; 1 für sehr viel mit Essen zu tun). 
Damit hätte der Satz „In der Mensa gibt es jeden Tag Currywurst mit Pommes“ an der ersten Stelle vielleicht eine 0,1, weil der Begriff „Mensa“ leicht mit Uni und Professoren konnotiert wird und die zweite Stelle würde bei 0,94 liegen, da es in dem Satz offensichtlich um das Essen handelt. 
In der Realität wird das Model sehr wahrscheinlich nicht so für Menschen offensichtlichen Merkmale lernen. Ein Grund dafür ist, dass das Model vor allem pro Eintrag eine linearkombination von verschiedenen Menschenoffensichtlichen Merkmalen lernen wird, also jede Zahl eine überlagerung verschiedener Eigenschaften darstellt. 
Eine forschungsrichtung, die versucht solche Modelausgaben Menschenlesbar zu gestalten liegt in der Explainable AI

Um die Ähnlichkeit von diesem Satz zu der Frage „“ zu bestimmen nutzen wir die Cosinus distanz als Maß. Es gibt auch die Euclidische Distanz, allerdings gestaltet sich dabei das Problem der Vector Normalisierung.


Diese Komplexen semantischen Unterschiede, oder Gemeinsamkeiten zu erkennen erfordert etwas mehr Raffinesse.

Andere Distanzmaßen:
Manhatten Distanz (nur x oder y Achse)
Hamming Distanz (Anzahl verschiedener Einträge)

\subsubsection{Euclidean Similarity}

Die Euklidische Distanz von zwei Vektoren kann man über den Satz des Pythagoras berechnen.
Dafür nimmt man für jede Dimension die Differenz beider Vektoren in dieser Dimension, quadriert diese und summiert alle Quadrate zusammen, um dann die quadratwurzel darüber zu ziehen.
Für die beiden Vektoren 
$\begin{pmatrix}0\\1\end{pmatrix}$
und 
$\begin{pmatrix}-1\\0\end{pmatrix}$
wäre die

Euklidische Distanz $\frac{1}{\sqrt{2}}$, da $\sqrt{(0-(-1))^2 + (1-0)^2}=\frac{1}{\sqrt{2}}$

Dieses Distanzmaß ist sensibel gegenüber der Länge der Vektoren.
Wenn die Vektoren nicht normiert wurden, kann die Euklidische Distanz sehr groß werden und die Ergebnisse einer Ähnlichkeitssuche verfälschen.


\subsubsection{Cosinus Similarity}

Ein weiteres Ähnlichkeitsmaß kann man über den Winkel zwischen zwei Vektoren definieren.
Dieser Winkel ist unanhängig davon, wie lang die Vektoren sind, immer gleich.
Die weitverbreiteste Methode um diesen Winkel zu messen, ist über die Cosinus Ähnlichkeit.
Diese berechnet den Cosinus des Winkels und kann einfach über die Formel

$\text{cosine\_similarity}(\mathbf{a}, \mathbf{b}) = \frac{\mathbf{a} \cdot \mathbf{b}}{\|\mathbf{a}\| \|\mathbf{b}\|}$

berechnet werden.
Dabei wird für beide Vektoren zunächst das Skalarprodukt bestimmt.
Das Skalarprodukt besitzt die Eigenschaft groß zu sein, wenn beide Vektoren in ähnliche Richtungen zeigen und kleiner, wenn beide Vektoren in unterschiedliche Richtungen zeigen.
Dabei hat die Länge der unterschiedlichen Vektoren einen Einfluss auf die Größe des Skalarproduktes.
Um dieser Verzerrung entgegenzuwirken, wird das Skalarprodukt durch das Produkt der Beträge der Vektoren geteilt.
Dadurch erhält man den cosinus des Winkels zwischen diesen beiden Vektoren.

Wenn beide Vektoren vorher normiert wurden, das heißt der Betrag der Vektoren gleich Eins ist, ist die Cosinus Distanz gleich der Skalarprodukt Distanz der beiden Vektoren.
Außerdem kann in diesem Fall die Euklidische Distanz asu der Cosinus Distanz errechnet werden durch die Formel: 

$\text{Euclidean distance} = \sqrt{2 - 2 \cos(\theta)}$



\subsection{Anreichern der Segmente}

Das Ranking der einzelnen Sätze liefert eine Auswahl der besten Kandidaten für den Podcast.
Einzelne Sätze, die aus verschiedenen Podcast Episoden stammen ohne Kontext hintereinander abzuspielen bietet für den Zuhörer nur ein mäßiges Hörerlebnis. 
Es fehlt der Kontext zu den einzelnen Informationen.
Zum Besipiel bekommt man für die Suchanfrage "Geschichte Amsterdam" mit dem TF-IDF Ansatz Sätze wie "Amsterdam, das bedeutet unbeschwerte Kinderjahre" oder "Amsterdam gefiel ihm".
Die Sätze an sich bieten kaum interessante Informationen.
Dem Zuhörer stellen sich sogar noch mehr Fragen, zum Beispiel für wen Amsterdam unbeschwerte Kinderjahre bedeuten oder wem Amsterdam gefiel.

Um dem Zuhörer mehr Informationen zu geben kann man die Größe der einzelnen Segmente Anpassen.
Dazu kann man mehrere Ansätze betrachten.
Der einfachste Ansatz ist, für jeden einzelnen Satz die umgebenden Sätze davor und dahinter miteinzubeziehen.
Die Anzahl der umgebenden Sätze ist dann ein Hyperparameter dieses Systems und kann vom Nutzer durch den Parameter Segmentlänge eingestellt werden, welher die Anzahl der Sätze in einem Segment angibt.
Falls der auszuschneidende Satz am Anfang oder am Ende des Transkriptes vorkommt, und die Segmentlänge so eingestellt ist, dass mehr Sätze als möglich dem Segment hinzugefügt werden sollten, so wird das Segment an der Transkriptgrenze abgeschnitten.
Die Evaluation der besten Segmentlänge wurde in dieser Arbeit nicht ausgeführt, als defaultwert ist für die Segmentlänge 5 eingestellt.

Ein weiterer Ansatz wäre auch hier ein mächtiges LLM, wie ChatGPT zu benutzen, um die richtige Segmentlänge für jedes Segment individuell einzustellen.
Dazu kann man das LLM instruieren, aus einer sehr großen Anzahl an Kontextsätzen (zum Beispiel 50) oder dem ganzen Transkript einer Podcast Episode und der dazugehörigen Frage, die Anzahl der Kontextsätze auf das wesentliche zu beschränken.

% Dieser Ansatz würde allerdings sehr zeit- und rechenaufwändig sein.
% Wenn man als LLM ChatGPT benutzen würde, dann würden pro einzelnem Segment ca. 50 Sätze (entspricht ca. 500 Tokens) ca. 0.00025 \$ kosten entstehen.

In dieser Arbeit wurde dieser Ansatz ausprobiert mithilfe eines Promptes wie 

Je nachdem welches LLM man dafür benutzt könnten Zeit und kostenfaktoren eine Rolle spielen.


\subsection{Reranking mit ChatGPT}

Nachdem nun die einzelnen Sätze zu gößeren Segmenten erweitert wurden, kann man auch die Reihenfolge der einzelnen Segmente anpassen.
Wenn man sich beispielsweise über die "Geschichte von Amsterdam" informieren will, kommen dazu verschiedene Ausschnitte aus der Zeit der Gründung der Niederlande in 1581, den Besuchen Peter des Großen in Amsterdam im Jahr 1697 oder der Verfolgung der Juden im Zweiten Weltkrieg.
Die Reihenfolge dieser Ereignisse wird im Retrival Schritt dadurch bestimmt, wie stark die Ähnlichkeit zwischen diesem Segent und der Frage ist.
In diesem Fall wäre es sehr nützlich die Reihenfolge so umzuändern, dass die Segmente zeitlich sortiert wären.
In anderen Fällen könnte es Sinnvoll sein, dass Segmente hintereinander erscheinen, die einen Inhaltlichen Zusammenhang besitzen.
Zum Beispiel würde zu dem Thema "Mauerfall Berlin" mehrere Segmente vorkommen, die sich auch mit der DDR befassen.
In diesem Fall währe es für Zuhörende spannend diese Segmente hintereinander zu platzieren, um dem Podcast flüssiger und zusammenhängender zu gestalten.

Ein solches Reranking der einzelnen Segmente kann mithilfe von leistungsstarken LLMs wie ChatGPT erreicht werden.
Dazu werden die einzelnen Segmente nummeriert an die Inferenz API von ChatGPT geschickt und das LLM soll die neue Reihenfolge als Liste zurückgeben.
Dafür wird der JSON Modus von ChatGPT genutzt, welcher das LLM dazu bringt, die Antwort als JSON String zurückzugeben.
Ein Beispielprompt kann im Anhang nachgelesen werden \autoref{ch:chatgpt-reranking}.

Da dies eine relativ einfache Aufgabe ist, in der nur eine Liste mit wenigen Zahlen zurückgegeben werden muss, wird in diesem Schritt auf Techniken des Prompt engineerings verzichtet.




\section{Audio-Zusammensetzung}


Für die Bearbeitung von Audio files in Python bietet sich das Python-Modul Pydub an. 
Mit diesem Modul kann ein Audiofile ähnlich wie ein Array behandelt werden.
Wenn sich zum Beispiel in einem Audiofile ein wichtiges Segment von Sekunde 34 bis Sekunde 64 erstreckt,  kann dort einfach die Start- und Endzeit in Arrayschreibweise angegeben werden.
Im Hintergrund verwendet dieses Modul Software-Bibliotheken des Softwareprojekts FFmpeg, welche umfangreichen Support für die Bearbeitung fast aller Audioformate besitzt.\cite{ffmpeg}
Für die Zeitstempel der Start und End Zeit jedes Audiosegments nehmen wir die Daten aus den vorher aus der SQLite extrahierten relevanten Segmenten.
Diese werden dann als extra Audiofiles als WAV Datein in einem seperaten Ordner abgespeichert, um einem Qualitätsverlust durch die Codierung des verlustbehafteten Codierungsformat MP3 vorzubeugen.

Um die Audios nun wieder zusammenzusetzen, verwenden wir das gleiche Modul Pydub. 
Es bieten sich mehrere Möglichkeiten an, die Audiosegmente zusammenzusetzen. 
Der primitivste Ansatz wäre, die Segmente einfach ohne Pause hintereinander abspielen. 
Die einzelnen Segmente beginnen und enden meist abrubt und das hintereinanderschalten mehrerer Segmente ohne Pause führt zu verwirrungen, wo ein Segment endet und wo das nächste anfängt.
Dafür bietet sich ein kurzer Signalton zwischen den einzelnen Audiosegmenten an. 
Dieser sollte nicht nervig sein, da er dem Hörer öfter vorgespielt wird. 
In dieser Arbeit wurde ein kleiner Jingle, der zum Anfang einer Episode abgespielt wird als Signalton verwendet.

Eine weitere Möglichkeit wäre, zwischen jedem Segment dem Hörer eine kurze Vorstellung der Episode und der Sprecher*in zu ermöglichen oder sogar Kontext zu dieser zu geben. 
Dazu könnte eine kurze Einleitung zu jedem Segment mit einer synthetisch generierten Stimme erstellt werden.
Dieser Ansatz wurde hier aber nicht weiter verfolgt.

\section{Weiterführende Themenvorschläge}

Um den Zuhörenden die Möglichkeit zu geben, auf verschiedene Themen, die im Podcast erwähnt wurden, weiter einzugehen, wurden entsprechende Themenvorschläge mithilfe von ChatGPT generiert.
Wenn zum Beispiel in einem Podcast zur "Geschichte von Amsterdam" einzelne Segmente über die Anfangszeit der Niederlande handeln, könnte man sich in einer weiterführenen Episode zum Beispiel über die "Gründung der Niederlande" informieren.
Zu diesem Zweck werden für jede generierte Podcastepisode fünf weiterführende Themenvorschläge von ChatGPT generiert, die zu den Segmenten passen.
Dazu wird wieder ChatGPT3.5 im JSON Modus verwendet.
Ein Beispielprompt ist hier zu lesen \autoref{ch:chatgpt-reranking}.
Die Themen werden explizit auf 1-3 Wörter beschränkt, da sonst manchmal ganze Sätze als Themenvorschläge geführt werden, wie zum Beispiel "Die Erfahrungen von Juden in Amsterdam während der Nazibesetzung".
Die Antwort von ChatGPT besteht aus einem JSON Array, welches die weiteführenden Themen enthält.
Die einzelnen Themen können je nach Auslieferungsart des Systems zum Beispiel als Buttons angezeigt werden, die eine erneute Suche auslösen, sobald ein nutzende Person ihn drückt.

\section{Auslieferung}

Das System wird in diesem Prototyp als Webservice zur Nutzung angeboten. 
Für das Deployment dieses Tools wurde das Webframework Flask genutzt.
Flask ist ein Web Service Gateway Interface Server (WSGI), welches das Bereitstellen von Webseiten über die WSGI Schnittstelle ermöglicht, welche dann von einem HTTP Server ausgeliefert werden können.
In dieser Arbeit wird dafür der WSGI HTTP Server gunicorn verwendet.
Gunicorn ist für Unix Systeme geeignet, einfach zu konfigurieren und bietet support für mehrere Worker, die mehrere Anfragen gleichzeitig bearbeiten können.

Für die Auslieferung wurde eine API und eine Webseite entwickelt.

\subsection{API}

Über die API kann der Podcast Generator einfach von anderen Anwendungen aufgerufen werden.
Die API wird aufgerufen über eine GET Request auf die unterseite /api .

Als Parameter akzeptiert die API einen String "text", welcher die Frage des Nutzers angibt.
Außerdem kann über den Parameter "time" ein Integerwert angegeben werden, welcher die Zeit des Podcasts in Minuten angibt.
Der optionale Parameter "segment-length" kann als Integer übergeben werden und bestimmt die Länge der einzelnen Segmente.

Die API gibt bei erfolgreicher Verarbeitung den Statuscode 200 zurück und liefert als Inhalt ein JSON String zurück der eine einzige Variable "url" enthält.
Diese URL verweist auf das generierte MP3 file, das ab diesem Zeitpunkt unter der Adresse /static/audios verfügbar ist.

Als Demonstration wurde außerdem ein Telegram-Bot entwickelt der die API benutzt, um damit die automatische Podcastepisoden zu erstellen.
Der Telegram-Bot ist öffentlich verfügbar und kann über die Adresse https://t.me/PodcastGenerator gefunden werden.

\subsection{Design Webseite}

Die Webseite des Podcast Generators bieten einen einfachen Weg das System zu benutzen.
Es gibt die beiden Input Felder Thema und Zeit, und einen Start Button, bei dem die Generierung der Podcasts startet.
Nachdem die Podcastepisode fertig generiert wurde, wird der vorher ausgegraute Audioplayer aktiv.
Dann können Nutzende die Audiodatei mithilfe des Players anhören.
Außerdem ist unter/neben dem Audioplayer eine Box mit den Transkriptabschnitten des Podcasts, sortiert nach der Erscheinung in der generierten Episode.
Diese Transkriptabschnitte können zur Navigation innerhalb der Podcastepisode verwendet werden.


Das Design der Webseite beruht auf einem Template von https://github.com/muhammed/mini-player.
Dieses Template wurde erweitert, durch einen Suchbereich und einen Transkript Bereich.




\section{Erstellung einer Podcast Episode}

Erfolgreiche Podcasts zu erstellen benötigt viele einzelne Schritte.
Thema:
Am Anfang benötigt man immer eine Idee, die den Podcast bestimmt.
Das kann die Abhandlung eines Themas oder das halten an ein bestimmtes Format sein.
Vorbereitung:
Dann muss eventuell ein Skript vorgeschrieben werden, Gäste eingeladen werden oder das die Audio-Aufnahmebedingungen geklärt werden.
Zur vorbereitung von INterview Podcasts muss sich auf den jeweiligen gegenüber vorbereitet, Fragen formuliert und hintergrundwissen recherchiert werden.
Aufnahme:
Für die Aufnahme müssen die Sprecher vor Ort oder Remote sprechen.
Es gibt Audio und Video Podcasts
Nachbereitung/Editierung:
Zur Nachbereitung gehört das Anpassen der Lautstärke, herausschneiden von ungewünschten Abschnitten, Einfügen von Geräuschen oder zusätzlichen passagen.
Shownotes erstellen:
Der Podcast sollte transkribiert werden und eine Zusammenfassung erstellt werden.
Showbild erstellen:
Ein Bild für diese Episode erstellen.
Werbung schalten:
Kleine Teaser erstellen, die man z.B. auf Social Media teilen kann.

\section{Podcasts als Grundlage}

Es sollten nicht die vortragenden Personen wichtig sein und sie nicht emotional oder persönlich. 
Als Audioquelle kommen vor allem wissensbasierte Podcasts in Frage. 
Wissensbasierte Podcasts bieten als Audioform die besten qualitativen Inhalt für die Audiosegmente, wenn sie 

Als Anbieter von Audiomaterial bieten sich zum Beispiel YouTube oder Spotify an, die sehr viele 
Videos wie zum Beispiel von Youtube, setzen oft vorraus, dass der Zuschauer auch das Videomaterial sehen kann und somit würde nur das Hören der Audiospur zu verwirrung führen.
Für die Grundlage der Audiosegmente bieten sich insbesondere wissensbasierte Podcasts an, die den Zuhörenden Informationen vermitteln wollen, wenn sie 

Dabei liegt die Nutzung der ARD-Audiothek mit 17,9\% auf Platz vier hinter Spotify, Youtube und Amazon Music \cite{mindline-media2023}.

Im Appstore und im Google Playstore hat die App der ARD-Audiothek jeweils über eine Million Downloads.
\cite{gotting2023}

\section{KI in Podcasts}

Künstliche Intelligenz verändert die Branche des Podcastings in vielerlei Hinsicht. 

Transkriptionsmodelle wie Whisper sind in der Lage live Transkriptionen der Podcasts zu erstellen, die eine Qualität besitzen, die mit professionellen menschlichen Transkriptoren mithalten können \cite{radford}.
Diese können außerdem verschiedene Stimmen unterscheiden und die Emotionen der Sprecher erkennen, was es in der Nachbereitung eines Podcasts erheblich erleichtert, bestimmte Stellen zu finden \cite{wagner2023}
Es gibt Ansätze, KI gestützt Teaser von längeren Podcast Episoden zu erstellen, welche dann zu Werbezwecken in Sozial Media geteilt werden können. \cite{wang2023}

Ein großes Entwicklungsfeld in der Podcastbranche ist die komplett automatische Generierung von Podcasts. Die Technologie der automatischen Stimmengenerierung ist soweit fortgeschritten, dass sich künstlich generierte Stimmen fast so gut anhören wie echte Stimmen \cite{shi2023}.

Laut der Plattform Podcastle, die Software für Aufnahme und Editierung von Podcasts herstellt, 
erreichen heute schon AI-basierte Podcasts rund 45 Millionen US-Amerikaner \cite{podcastle2023}.
Der Podcast "Hacker News Recap" ist ein vollkommen von AI produzierter Podcast und erreicht in vielen Ländern wie Schweden oder Italien die Top 100 bei Apple Podcasts in der Kategorie Daily News \cite{chartable}.
In Deutschland ist der Podcast immerhin auf Platz 169.

\subsection{Fraunhofer}

Seit 2015 arbeitet die ARD mit dem Fraunhofer-Institut Institut für Intelligente Analyse- und Informationssysteme (IAIS) zusammen, um „Erschließung von Mediendaten zu forcieren und dabei den Schwerpunkt auf maschinelle Verfahren zu legen“ [1]
Ein Teil dieses Projektes bezieht sich auf das Audio-Mining. 
Das Fraunhofer IAIS entwickelte dafür ein System, welches die Audiodatein transkribiert und dabei „in der kompletten ARD, bei Deutschlandradio sowie im ZDF im Einsatz [ist]“. 
Leider legt das FraunhoferIAIS nicht offen, welche Technologie es dafür verwendet. 
Die Transkripte lassen sich allerdings sehr einfach über eine Graphql Schnittstelle abfragen. 

\subsection{Microsoft Translate}

Eine weitere Möglichkeit zur Audiotranskription bietet Microsoft Translate. 
Soweit man einen Microsoft 365 Account besitzt, kann man in dem Webinterface von Microsoft word eine Transkriptionsfunktion benutzen. 
Dafür müssen die Audiofiles zunächst auf Microsoft Onedrive hochgeladen werden und können dann mit einem Klick übersetzt werden. 
Microsoft Word stellt dann sogar Timestamps  zur Verfügung für das ganze Dokument. 
Die Qualität ist außerdem besser als bei kostenlosen Open-Source Alternativen. 
Dafür skaliert diese Art der Transkription schlecht für größere Datenmengen, da sämtliche files zunächst bei OneDrive hochgeladen werden müssen und dann jedes File von Hand ausgewählt, in Word eingebunden, transkribiert werden und dann abgespeichert werden müssen. 

\subsection{Satzbildung}

Für Retrieval funktionen ist es sinnvoll, mehrere Wörter zusammenzufassen.
Wenn man einen Algorithmus hat, der gezielt Wörter im Korpus suchen kann, ist es Wünschenswert nicht nur exakt dieselben Wörter zu suchen, sondern auch verwandte Wörter.
Zum Beispiel sollte die Suche nach dem Wort "Wanderer" auch Ergebisse für die Worte "Wandererin", "Wanderung" oder "wandern" enthalten, nicht aber das Wort "Wand".


\subsection{weitere Schritte}


Eine bekannte Bibliothek für Nearest Neighbour Searches ist Annoy, die unter anderem bei Spotify für die Recommendations von Songs verwendet wird. [Quelle]
Eine weitere bekannte bekannte Bibliothek für Nearest Neighbour Searches ist FAISS (Facebook AI Similarity Search)

\section{Milvus}

Vektordatenbanken entwickeln sich in den letzten Jahren stark weiter.
In diesem Projekt wurde zunächst die Vektordatenbank Milvus betrachtet.
Milvus kann sehr gut auf große Datenmengen skalieren und wird deshalb in vielen großen Unternehmen, wie Nvidia, Paypal oder ebay eingesetzt. 
Außerdem bietet Milvus Unterstützung für eine clusterbasierte Struktur, in der einzelne Container dynamisch zusammenarbeiten können. 
Dadurch wird eine gute Skalierbarkeit für große Datenmengen erreicht. 
Für kleinere Projekte ist der Setup-Aufwand sehr groß und die Lernkurve sehr steil.

Pinecone, Zilliz, Qdrant

Außerdem gibt es eine Erweiterung für die PostgreSQL Datenbank namens pg-Vector

Die Vektordatenbank Redis

Durch die Neuheit der Vektordatenbanken bedingt, gibt es kaum Vergleiche zwischen diesen.
\cite{blueteamai}


In dieser Arbeit wird die Vektordatenbank Milvus verwendet.
Milvus ist eine Open-Source Vektordatenbank die von dem Unternehmen Zilliz entwickelt wird.
Laut eigenen Angaben ist sie die am weitseten fortgeschrittene Vektordatenbank und wird von vielen Unternehmen, wie Nvidia, Paypal oder ebay benutzt.

\section{spaCy vs. NLKT}

Es gibt auch noch die beliebte Bibliothek NLKT, die sich aber eher auf das Unterrichten von NLP spezialisiert hat.
Die Bibliothek spaCy ist eher für den produktiven Einsatz geeignet.

\section{ChatGPT ist zu teuer}

Dieser Ansatz würde allerdings sehr zeit- und rechenaufwändig sein.
Wenn man als LLM ChatGPT benutzen würde, dann würden pro einzelnem Segment ca. 50 Sätze (entspricht ca. 500 Tokens) ca. 0.00025 \$ kosten entstehen.

ChatGPT von OpenAI, welcher auf einem LLM beruht, das auf ca. 175 Milliarden Parameter trainiert wurde. [https://www.ankursnewsletter.com/p/gpt-4-gpt-3-and-gpt-35-turbo-a-review]

\section{embedding}
Dazu werden die einzelnen Segmente mit den verschiedenen Modellen embedded.
Am Anfang des Segments kann noch einmal der Titel der Episode angefügt werden, was eventuell die Performance steigert.\cite{jones2021}

\section{Distanzmaße}

Um die Ähnlichkeit von diesem Satz zu der Frage „“ zu bestimmen, nutzen wir die Kosinusdistanz als Maß.
Es gibt auch die euklidische Distanz, allerdings gestaltet sich dabei das Problem der Vektornormalisierung als schwierig.

Diese komplexen semantischen Unterschiede oder Gemeinsamkeiten zu erkennen, erfordert etwas mehr Raffinesse.

Andere Distanzmaße sind:

Manhattan-Distanz (nur x- oder y-Achse)
Hamming-Distanz (Anzahl verschiedener Einträge)
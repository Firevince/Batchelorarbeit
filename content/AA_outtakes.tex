\section{Erstellung einer Podcast Episode}

Erfolgreiche Podcasts zu erstellen benötigt viele einzelne Schritte.
Thema:
Am Anfang benötigt man immer eine Idee, die den Podcast bestimmt.
Das kann die Abhandlung eines Themas oder das halten an ein bestimmtes Format sein.
Vorbereitung:
Dann muss eventuell ein Skript vorgeschrieben werden, Gäste eingeladen werden oder das die Audio-Aufnahmebedingungen geklärt werden.
Zur vorbereitung von INterview Podcasts muss sich auf den jeweiligen gegenüber vorbereitet, Fragen formuliert und hintergrundwissen recherchiert werden.
Aufnahme:
Für die Aufnahme müssen die Sprecher vor Ort oder Remote sprechen.
Es gibt Audio und Video Podcasts
Nachbereitung/Editierung:
Zur Nachbereitung gehört das Anpassen der Lautstärke, herausschneiden von ungewünschten Abschnitten, Einfügen von Geräuschen oder zusätzlichen passagen.
Shownotes erstellen:
Der Podcast sollte transkribiert werden und eine Zusammenfassung erstellt werden.
Showbild erstellen:
Ein Bild für diese Episode erstellen.
Werbung schalten:
Kleine Teaser erstellen, die man z.B. auf Social Media teilen kann.

\section{Podcasts als Grundlage}

Es sollten nicht die vortragenden Personen wichtig sein und sie nicht emotional oder persönlich. 
Als Audioquelle kommen vor allem wissensbasierte Podcasts in Frage. 
Wissensbasierte Podcasts bieten als Audioform die besten qualitativen Inhalt für die Audiosegmente, wenn sie 

Als Anbieter von Audiomaterial bieten sich zum Beispiel YouTube oder Spotify an, die sehr viele 
Videos wie zum Beispiel von Youtube, setzen oft vorraus, dass der Zuschauer auch das Videomaterial sehen kann und somit würde nur das Hören der Audiospur zu verwirrung führen.
Für die Grundlage der Audiosegmente bieten sich insbesondere wissensbasierte Podcasts an, die den Zuhörenden Informationen vermitteln wollen, wenn sie 

Dabei liegt die Nutzung der ARD-Audiothek mit 17,9\% auf Platz vier hinter Spotify, Youtube und Amazon Music \cite{mindline-media2023}.

Im Appstore und im Google Playstore hat die App der ARD-Audiothek jeweils über eine Million Downloads.
\cite{gotting2023}

\section{KI in Podcasts}

Künstliche Intelligenz verändert die Branche des Podcastings in vielerlei Hinsicht. 

Transkriptionsmodelle wie Whisper sind in der Lage live Transkriptionen der Podcasts zu erstellen, die eine Qualität besitzen, die mit professionellen menschlichen Transkriptoren mithalten können \cite{radford}.
Diese können außerdem verschiedene Stimmen unterscheiden und die Emotionen der Sprecher erkennen, was es in der Nachbereitung eines Podcasts erheblich erleichtert, bestimmte Stellen zu finden \cite{wagner2023}
Es gibt Ansätze, KI gestützt Teaser von längeren Podcast Episoden zu erstellen, welche dann zu Werbezwecken in Sozial Media geteilt werden können. \cite{wang2023}

Ein großes Entwicklungsfeld in der Podcastbranche ist die komplett automatische Generierung von Podcasts. Die Technologie der automatischen Stimmengenerierung ist soweit fortgeschritten, dass sich künstlich generierte Stimmen fast so gut anhören wie echte Stimmen \cite{shi2023}.

Laut der Plattform Podcastle, die Software für Aufnahme und Editierung von Podcasts herstellt, 
erreichen heute schon AI-basierte Podcasts rund 45 Millionen US-Amerikaner \cite{podcastle2023}.
Der Podcast "Hacker News Recap" ist ein vollkommen von AI produzierter Podcast und erreicht in vielen Ländern wie Schweden oder Italien die Top 100 bei Apple Podcasts in der Kategorie Daily News \cite{chartable}.
In Deutschland ist der Podcast immerhin auf Platz 169.

\subsection{Fraunhofer}

Seit 2015 arbeitet die ARD mit dem Fraunhofer-Institut Institut für Intelligente Analyse- und Informationssysteme (IAIS) zusammen, um „Erschließung von Mediendaten zu forcieren und dabei den Schwerpunkt auf maschinelle Verfahren zu legen“ [1]
Ein Teil dieses Projektes bezieht sich auf das Audio-Mining. 
Das Fraunhofer IAIS entwickelte dafür ein System, welches die Audiodatein transkribiert und dabei „in der kompletten ARD, bei Deutschlandradio sowie im ZDF im Einsatz [ist]“. 
Leider legt das FraunhoferIAIS nicht offen, welche Technologie es dafür verwendet. 
Die Transkripte lassen sich allerdings sehr einfach über eine Graphql Schnittstelle abfragen. 

\subsection{Microsoft Translate}

Eine weitere Möglichkeit zur Audiotranskription bietet Microsoft Translate. 
Soweit man einen Microsoft 365 Account besitzt, kann man in dem Webinterface von Microsoft word eine Transkriptionsfunktion benutzen. 
Dafür müssen die Audiofiles zunächst auf Microsoft Onedrive hochgeladen werden und können dann mit einem Klick übersetzt werden. 
Microsoft Word stellt dann sogar Timestamps  zur Verfügung für das ganze Dokument. 
Die Qualität ist außerdem besser als bei kostenlosen Open-Source Alternativen. 
Dafür skaliert diese Art der Transkription schlecht für größere Datenmengen, da sämtliche files zunächst bei OneDrive hochgeladen werden müssen und dann jedes File von Hand ausgewählt, in Word eingebunden, transkribiert werden und dann abgespeichert werden müssen. 

\subsection{Satzbildung}

Für Retrieval funktionen ist es sinnvoll, mehrere Wörter zusammenzufassen.
Wenn man einen Algorithmus hat, der gezielt Wörter im Korpus suchen kann, ist es Wünschenswert nicht nur exakt dieselben Wörter zu suchen, sondern auch verwandte Wörter.
Zum Beispiel sollte die Suche nach dem Wort "Wanderer" auch Ergebisse für die Worte "Wandererin", "Wanderung" oder "wandern" enthalten, nicht aber das Wort "Wand".


\subsection{weitere Schritte}


Eine bekannte Bibliothek für Nearest Neighbour Searches ist Annoy, die unter anderem bei Spotify für die Recommendations von Songs verwendet wird. [Quelle]
Eine weitere bekannte bekannte Bibliothek für Nearest Neighbour Searches ist FAISS (Facebook AI Similarity Search)

\section{Milvus}

Vektordatenbanken entwickeln sich in den letzten Jahren stark weiter.
In diesem Projekt wurde zunächst die Vektordatenbank Milvus betrachtet.
Milvus kann sehr gut auf große Datenmengen skalieren und wird deshalb in vielen großen Unternehmen, wie Nvidia, Paypal oder ebay eingesetzt. 
Außerdem bietet Milvus Unterstützung für eine clusterbasierte Struktur, in der einzelne Container dynamisch zusammenarbeiten können. 
Dadurch wird eine gute Skalierbarkeit für große Datenmengen erreicht. 
Für kleinere Projekte ist der Setup-Aufwand sehr groß und die Lernkurve sehr steil.

Pinecone, Zilliz, Qdrant

Außerdem gibt es eine Erweiterung für die PostgreSQL Datenbank namens pg-Vector

Die Vektordatenbank Redis

Durch die Neuheit der Vektordatenbanken bedingt, gibt es kaum Vergleiche zwischen diesen.
\cite{blueteamai}


In dieser Arbeit wird die Vektordatenbank Milvus verwendet.
Milvus ist eine Open-Source Vektordatenbank die von dem Unternehmen Zilliz entwickelt wird.
Laut eigenen Angaben ist sie die am weitseten fortgeschrittene Vektordatenbank und wird von vielen Unternehmen, wie Nvidia, Paypal oder ebay benutzt.

\section{spaCy vs. NLKT}

Es gibt auch noch die beliebte Bibliothek NLKT, die sich aber eher auf das Unterrichten von NLP spezialisiert hat.
Die Bibliothek spaCy ist eher für den produktiven Einsatz geeignet.

\section{ChatGPT ist zu teuer}

Dieser Ansatz würde allerdings sehr zeit- und rechenaufwändig sein.
Wenn man als LLM ChatGPT benutzen würde, dann würden pro einzelnem Segment ca. 50 Sätze (entspricht ca. 500 Tokens) ca. 0.00025 \$ kosten entstehen.

ChatGPT von OpenAI, welcher auf einem LLM beruht, das auf ca. 175 Milliarden Parameter trainiert wurde. [https://www.ankursnewsletter.com/p/gpt-4-gpt-3-and-gpt-35-turbo-a-review]

\section{embedding}
Dazu werden die einzelnen Segmente mit den verschiedenen Modellen embedded.
Am Anfang des Segments kann noch einmal der Titel der Episode angefügt werden, was eventuell die Performance steigert.\cite{jones2021}

\section{Distanzmaße}

Um die Ähnlichkeit von diesem Satz zu der Frage „“ zu bestimmen, nutzen wir die Kosinusdistanz als Maß.
Es gibt auch die euklidische Distanz, allerdings gestaltet sich dabei das Problem der Vektornormalisierung als schwierig.

Diese komplexen semantischen Unterschiede oder Gemeinsamkeiten zu erkennen, erfordert etwas mehr Raffinesse.

Andere Distanzmaße sind:

Manhattan-Distanz (nur x- oder y-Achse)
Hamming-Distanz (Anzahl verschiedener Einträge)

\section{explainable AI}
Ein Versuch, die komplexen Features für Menschen zu vereinfachen kann mithilfe eines t-SNE Algorithmuses erreicht werden.
Eine Forschungsrichtung, die versucht, solche Modellausgaben menschenlesbar zu gestalten, liegt in der Explainable AI~\cite{hassija2024}.

\section{BERT Embeddings}

Um einen Embeddingvektor zu erstellen, benutzen wir das BERT Model. BERT, das Akronym für Bidirectional Encoder Representations from Transformer, ist ein Sprachmodel, das 2018 von Google entwickelt, und zur Benutzung freigegeben wurde. 
BERT ist ein Neuronales Netzwerk mit 12 Schichten, das für zwei verschiedene Aufgaben gleichzeitig trainiert wurde. Zum einen wurde es auf eine Masked Language Modeling Aufgabe und zum Anderen auf eine Next Sentence Prediction trainiert. 

Masked Language Modeling
Bei dieser Aufgabe soll das Model versuchen, aus dem Kontext eines Satzes ein maskiertes Wort in diesem Satz vorherzusagen. Dafür wird dem Model ein Satz gegeben, in dem zufällige Wörter einfach versteckt werden und das Model soll für diese Wörtereine Vorhersage treffen.

\section{LLama2 Embeddings}

Ein sehr Leistungsfähiges LLM ist das von Meta entwickelte LLama und deren Nachfolger LLama2. \cite{touvron2023}

\subsubsection{Keywordsuche}

Eine Möglichkeit bietet sich in der Keywordsuche. 
Hierbei wird einfach überprüft, ob sich ein Keyword in einem der Dokumente wiederfindet. Ist die möchte ein User beispielsweise einen zusammengeschnittene Podcast Episode über \qt{Zugspitze}, so schaut das System, in welchen Episodensegmenten das Wort \qt{Zugspitze} auftaucht, und gibt diese zurück. 
Schwieriger wird es, wenn die Useranfrage mehrere Wörter beinhaltet. 
Möchte sich der User über das Thema \qt{Zugspitze wandern} informieren so müsste zunächst untersucht werden, welche Dokumente beide Worte enthalten, welche nur eines der beiden enthalten. 
Dann müsste man dementsprechend auch ein Algorithmus entwickeln, der diese dann sinnvoll hierarchisiert. 
Das Wort \qt{Zugspitze}

\subsubsection{TF-IDF}

Einen solchen Ansatz bietet das TF-IDF Maß (Term Frequency - Inverse Document Frequency). 
Im Bereich des NLP verwendet man das TF-IDF Maß um zu untersuchen welche Wörter in verschiedenen Dokumenten welche Gewichtung erfahren. 
Dazu wird zunächst die TF-Matrix, also die Term Frequenzy Matrix berechnet. 
Hierbei wird erst das Vokabular ermittelt, also die Gesamtheit aller Tokens (Wörter) die es in allen Dokumenten (Transkript Segmenten) des Korpuses (alle heruntergeladenen Episoden) gibt. 
Dann wird für jedes einzelne Segment die Anzahl jeder in ihm auftretenden Tokens ermittelt. 
Für den Satz: „Auf der Zugspitze gibt es viele Wanderer, die die Zugspitze lieben“. 
In diesem Fall würde in der TF Matrix an der Stelle Zugspitze eine 2 Stehen, in der Zeile Wandern aber 0, da zwar das Wort Wanderer, aber nicht das Wort wandern vorkommt. 
Da diese beiden Worte aber sehr ähnlich sind und der User bei einer Anfrage nicht immer nach verschiedenen Versionen eines Wortes suchen will, um dann ein zufriedenstellendes Audio zu erhalten

Da für exakte Keywortsuche solche Begriffe fast nie auftreten, lohnt es sich, 


Dabei gibt es allerdings keine Möglichkeit, die verschiedenen Treffer dieser suche nach Relevanz zu hierarchisieren. Sucht man zum Beispiel nach dem Stichwort \qt{Klimakrise} würden dabei mehrere Stunden Material zusammenkommen [QUELLE]. 
Man könnte nun einfach die Ersten Segmente nehmen, die zusammen die vorgegebene Zeit überbrücken. 
Allerdings ist dieser Ansatz wenig Vielversprechend. 

\section{PDFs auslesen}
da sie die exakte Wortwahl der Podcasts enthalten, als PDF-Format sind sie allerdings schwierig maschinell auszulesen und weiterhin


\section{modelauswahl}
TF-IDF - vergleich zu Keyword-suche
all-mini-LM-L6-v2 - klein, schnell, most downloaded~\cite{2024}
voyage-lite-02-instruct - 1024 dim - platz 2 bei Retrival auf MTEB (Platz 1 konnte nicht zum laufen gebracht werden) 
OpenAI text-embeddings-small - platz 27 auf MTEB - 1526 dim 

\section{Bewertungskriterien}


Die Aufgabe besteht darin, zu untersuchen, wie gut eine Suchfunktion mithilfe der Embeddings in der Lage ist, passende Informationen zu einem Thema zu extrahieren.

Für die Evaluation der verschiedenen Embeddings werden verschiedene Kriterien angelegt.
Einerseits müssen die extrahierten Segmente zu dem Thema passen und nicht irrelevante andere Themen behandeln.
Das ist der wichtigste Punkte bei der Evaluation.

Ein weiteres Kriterium ist der Inhaltliche Zusammenhang der einzelnen Segmente.
Die einzelnen Segmente sollten eine inhaltliche Verbindung aufweisen, sodass der/die Hörer*in nicht zwischen verschiedenen Themn hin und hergeworfen wird.
Zum Beispiel soll ein Podcast über \qt{Geschichte Amsterdam} nicht in einem Segment über die Gründung der Niederlande sprechen und im nächsten Segment davon handeln, wie sich Amsterdam in der Nazi Zeit verhalten hat.
Gleichzeitig sollen die Segmente auch nicht alle denselben Inhalt aufweisen und zum Beispiel in drei verschiedenen Segmenten wiederholen, dass die Niederlande im goldenen Zeitalter des 17. Jahrhunderts ein florierendes Handelsnetzwerk aufgebaut hatten.

\section{Prompt Engineering}

Reasoning
Json
GPT-4
beispielprompt


\section{Sentence Transformer Embeddings}

Das Sentence Transformer Projekt baut auf der Architektur von BERT auf. 
Es wird auch SBERT für Sentence BERT genannt. 
Uni Darmstadt
Haben verschiedene Modelle.

Unter dem 


\section{OpenAI Embeddings}

\href{https://twitter.com/Nils_Reimers/status/1487014195568775173}{twitter}

OpenAI stellt außer den Text (GPT-4) und Bild (DALLE) generierungs Modellen auch Modelle zur Embedding erstellung in Ihrer API vor.
Ada (1024 dimensions)
Babbage (2048 dimensions)
Curie (4096 dimensions)
Davinci (12288 dimensions)

\section{voyage}

über API
1024 Dimensionen

\section{elastic Search}

\chapter{Verwandte Literatur}\label{ch:related_work}

Im Bereich der automatisierten Podcasterstellung gibt es einige Versuche mittels künstlich generierter Texte und Stimmen einen eigenen Podcast zu erstellen.

In dem Artikel \qt{NewsPod: Automatic and Interactive News Podcasts}~\cite{laban2022} wird ein neuer Ansatz für die automatische Erstellung von Podcast-Episoden vorgestellt. 
Dazu wird ein interaktiver Sprachbot entwickelt, der zu bestimmten Nachrichten Fragen beantworten kann und mithilfe einer synthetisch generierten Stimme mit den nutzenden Personen interagiert.
Mehrere Machine Learning Systeme ermitteln den Inhalt von bestimmten Nachrichtenseiten und extrahieren daraus Fragestellungen, die den Inhalt des Textes widerspiegeln sollen. 
Die Autoren benutzen ein GPT-2 Sprachmodell, das auf Fragengenerierung trainiert wurde, um aus jedem Absatz 7 Fragen zu ermitteln. 
Ein weiteres Question-Answering Sprachmodell wird dann trainiert, um die Ausschnitte in den Artikeln zu finden, welche diese Fragen beantworten.  
Der Retrieval Step wird hier also nicht durch Embeddings, sondern durch ein Sprachmodell vollzogen.

Der wichtigste Aspekt dieses Artikels ist, dass die Anwendenden interaktiv mit der Software agieren und selbstgewählte Fragen mithilfe eines Mikrofons oder einer Tastatur stellen können.
Das Question-Answering Sprachmodell versucht dafür relevante Segmente aus mehreren Nachrichtenartikeln zu finden, die die Fragen der nutzenden Person beantworten.
Diese werden dann mithilfe einer synthetisch generierten Stimme von Googles Text-To-Speech API vorgelesen.

Die Autoren dieses Papers führten außerdem zwei Studien zur Nutzung dieses Systems durch.
Der Gegenstand der ersten Studie ist, inwieweit die Zufriedenheit einer Testgruppe mit der Erzählweise des Textes und der automatisch generierten Stimme des Sprechers korreliert. 
Darin konnten die Autoren feststellen, dass einer ihrer Ansätze, QA Best, so erfolgreich war, dass 80\% der Testpersonen angaben, dass sie dieses System in Zukunft nutzen würden, um Nachrichten zu konsumieren.
Die zweite Studie untersucht die Interaktion der Zuhörenden während der Benutzung des Systems. 
Diese Studie kam zu dem Schluss, dass zwar die Bereitschaft eigene Fragen zu stellen mit 85\% der Zuhörenden sehr hoch war, die Zufriedenheit der Testenden mit der Qualität der Antworten aber sehr gering ausfiel, da 76\% der Antworten als verwirrend eingestuft wurden.~\cite{laban2022}


In einem weiteren für die Aufgabenstellung relevanten Paper~\cite{jones2021} werden die Ergebnisse der Text Retrieval Conference (TREC) 2020 für die Podcastanalyse vorgestellt.
Für diese Aufgabe analysierten die Teilnehmer einen großen Datenbestand an Podcasttranskripten.
Die Teilnehmer versuchten aus über 100.000 Podcasttranskripten die wichtigsten Segmente zu verschiedenen Themen herauszufiltern.
Im Vorfeld wurden die Transkripte durch ein System zur Automatic Speech Recognition (ASR) erstellt.
Jedes Transkriptsegment ist dabei jeweils genau zwei Minuten lang und überlappt sich um eine Minute mit einem folgenden Segment.
Die entsprechenden Aufgabenstellungen sind in drei Kategorien eingeteilt: topical, re-finding und known items.
Bei der Kategorie topical wird verlangt, passende Segmente zu einem bestimmten Thema zu finden.
Beim re-finding geht es darum, einen zuvor bekannten Audioinhalt wiederzufinden.
Dabei waren nur Teile des Audioinhaltes oder bestimmte Rahmenbedingungen vorgegeben (z.B. eine Podcast-Episode, welche die Person vor einer Woche hörte).
In der letzten Kategorie den known items sind bereits der Titel bzw.\ weitere Metainformationen bekannt.
Die einzelnen Themen verfügten dabei außerdem noch über eine Beschreibung, die spezifiziert, was eine Testperson von der Suche mit diesem Prompt erwarten würde.


Insgesamt nahmen neun Teilnehmer an dieser Aufgabe teil und reichten eine Lösung ein.
Darunter Universitäten aus den USA und Dublin sowie ein Team des Musikstreaminganbieters Spotify.
Die Evaluation der Ergebnisse wurde manuell durchgeführt.
Verschiedene Gutachter des TREC bewerteten die Ergebnisse der Teilnehmer auf einer Skala von 5 (perfekt) bis 0 (nicht passend).
Am besten schnitten dabei die Lösungen der Universität Maryland ab, die zur Datenaufbereitung eine Mischung aus Stemming und Word2Vec benutzten und für die Retrievalfunktion die Search Engine Indri einsetzten.
Die Indri Search Engine wurde von der University of Massachusetts und Carnegie Mellon University aufgebaut, wird aber zurzeit nicht mehr weiterentwickelt~\cite{lemur}.


Speziell für deutsche Audioinhalte ist ein Artikel zu erwähnen, indem das Fraunhofer-Institut für Intelligente Anlyse- und Informationssysteme (IAIS) 2015 die Audiominig Plattform medas vorstellt~\cite{maroni2020}.
Diese soll für die ARD-Audiothek die Suchfunktionen für verschiedene Audioinhalte verbessern.
Dazu erstellten die Forscher ein System, dass diese Inhalte automatisch mit ASR transkribieren, eine Spracherkennung durchführen und Keywörter extrahieren kann.
Diese Daten sind über eine REST Schnittstelle abrufbar.
Allerdings sind viele der beschriebenen Technologien mittlerweile nicht mehr State-of-the-Art und spielen deswegen in dieser Arbeit kaum eine Rolle.~\cite{maroni2020}
In \autoref{ch:method} wird darauf näher eingegangen.

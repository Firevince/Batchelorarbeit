\chapter{Einleitung}\label{ch:intro}

\section{Motivation}

Podcasts sind für viele Menschen ein wichtiges Medium, um sich die Zeit zu vertreiben und sich über verschiedene Themen zu informieren. 
In Deutschland hören etwa 29\% der Menschen regelmäßig Podcasts~\cite{newman2022}.
In dieser Arbeit liegt der Fokus auf den Personen, die Podcasts hören, um sich zu verschiedenen Themen weiterzubilden.
Mittlerweile gibt es zu fast jedem Thema einen bestimmten Podcast, allein in Deutschland über 90.000~\cite{listennotes}.
Diese Menge an Podcasts ist für viele Menschen schwer zu überblicken.
Viele Suchfunktionen basieren nur auf den Metadaten der verschiedenen Podcasts und so werden im Zweifel nur Episoden gefunden, deren Titel oder Schlagworte am besten zur Anfrage passen~\cite{maroni2020}.
Oft passen diese Informationen aber leider nicht zu den Anfragen der Nutzenden.
In diesem Fall kann es besser sein, die tatsächlichen Inhalte einer Episode zu durchsuchen und den Nutzenden nur die für sie relevanten Ausschnitte zu liefern.
Außerdem gibt es kaum Möglichkeiten, die Informationen aus verschiedenen Podcasts zu bündeln und den Hörern eine Zusammenstellung verschiedener Audiosegmente aus verschiedenen Podcasts anzubieten.

In dieser Bachelorarbeit wird untersucht, wie aus umfangreichem Audiomaterial aus Radioprogrammen oder Podcasts ein eigener Podcast zusammengestellt werden kann, der relevante Ausschnitte aus einer Vielzahl von Quellen enthält.

Ein möglicher Anwendungsfall wäre eine Person, die sich über das Thema „Überfischung der Meere“ informieren möchte und dafür genau 20 Minuten während einer Autofahrt einplant. 
Das System erstellt nun einen Zusammenschnitt aus verschiedenen Podcast-Episoden zu diesem Thema, der 20 Minuten lang ist, und stellt ihn der Person zur Verfügung. 
Der Vorteil für die Nutzenden liegt darin, dass sie selbst das Thema auswählen und die exakte Länge festlegen können.
Außerdem wird das Thema von verschiedenen Sprechern aus unterschiedlichen Perspektiven erklärt, was zu einer Steigerung der Aufmerksamkeit führt~\cite{kang2012}.

\section{Zielsetzung}

Diese Bachelorarbeit ist in zwei Teile aufgeteilt.
Im ersten Teil der Arbeit wird beschrieben, wie ein Prototyp für ein System zur automatischen Podcastgenerierung aufgebaut sein könnte.
Dazu werden die einzelnen Mikroservices vorgestellt und die Wahl der verwendeten Technologien begründet.
In einigen Fällen werden mehrere unterschiedliche Services miteinander verglichen.
In anderen Fällen wird beschrieben, wie bei der Entstehung des Projektes bestimmte Technologien durch andere ersetzt wurden, da in der Zwischenzeit neue Erkenntnisse gewonnen worden sind.
Für die Auswahl der passenden Audiosegmente werden verschiedene Methoden des Natural Language Processing verwendet, insbesondere Text-Embeddings.
Außerdem werden die Fähigkeiten von Large Language Models genutzt, um die Qualität der generierten Podcast-Episoden zu verbessern.
Für die Interaktion mit dem Benutzer soll außerdem eine grafische Benutzeroberfläche bereitgestellt werden, die den Nutzenden die Auswahl eines Themas und die Länge der Podcast-Episode ermöglicht.

Im zweiten Teil der Arbeit geht es insbesondere um die Auswahl der richtigen Embeddings.
Dabei wird die Fähigkeit, relevante Segmente zu finden, anhand verschiedener Metriken evaluiert.
Es werden die Ausgaben verschiedener Embeddings miteinander verglichen und die Güte mithilfe eines Large Language Models bewertet.

\section{Überblick}

Diese Arbeit ist in acht Kapitel gegliedert.

Im ersten Kapitel werden die Zielsetzung, Motivation und ein kurzer Überblick dargelegt, während im zweiten Kapitel die relevante Literatur zusammengefasst wird.

Das dritte Kapitel erklärt die theoretischen Grundlagen, die für das Verständnis der später aufgeführten Technologien erforderlich sind. 
Besonderes Augenmerk wird dabei auf die Technologien der Embeddings und der Large Language Models gelegt.

Im vierten Kapitel geht es um die Beschaffung der Audiodaten, wobei verschiedene Methoden zur Transkription dieser Audiodaten beschrieben und begründet werden, welche Transkriptionsmethode für diese Arbeit gewählt wurde. 
Außerdem werden effiziente Wege für die Datenspeicherung diskutiert.

Die Architektur des Systems wird im fünften Kapitel dargestellt, wobei ein besonderer Fokus auf die semantische Analyse der Transkriptionen gelegt und verschiedene Aspekte des Natural Language Processing sowie der Large Language Models erörtert werden.

Im sechsten Kapitel werden verschiedene Methoden zur semantischen Analyse evaluiert, die verwendeten Modelle, die Wahl der Anzahl und Länge der Abschnitte sowie die finale Zusammensetzung dieser erklärt und begründet.

Ein Ausblick auf zukünftige Weiterentwicklungen wird im siebten Kapitel gegeben und im letzten Kapitel werden die Ergebnisse dieser Arbeit zusammengefasst.

\chapter{Einleitung}\label{ch:intro}

\section{Motivation}

Podcasts sind für viele Menschen ein wichtiges Medium, um sich die Zeit zu vertreiben und sich über verschiedene Themen zu informieren. 
In Deutschland hören etwa 29\% der Menschen regelmäßig Podcasts~\cite{newman2022}.
In dieser Arbeit liegt der Fokus auf den Personen, die Podcasts hören, um sich zu verschiedenen Themen weiterzubilden.
Mittlerweile gibt es zu fast jedem Thema einen bestimmten Podcast, allein in Deutschland über 90.000~\cite{listennotes}.
Diese Menge an Podcasts ist für viele Menschen schwer zu überblicken.
Die meisten Suchfunktionen basieren nur auf den Metadaten der verschiedenen Podcasts und so werden im Zweifel nur Episoden gefunden, deren Titel oder Schlagworte am besten zur Anfrage passen.
Oft passen diese Informationen aber leider nicht zu den Anfragen der Nutzenden.
In diesem Fall kann es besser sein, die tatsächlichen Inhalte einer Episode zu durchsuchen und den Nutzenden nur die für sie relevanten Ausschnitte zu liefern.
Außerdem gibt es kaum Möglichkeiten, die Informationen aus verschiedenen Podcasts zu bündeln und den Hörern eine Zusammenstellung verschiedener Audiosegmente aus verschiedenen Podcasts anzubieten.

In dieser Bachelorarbeit wird untersucht, wie aus umfangreichem Audiomaterial aus Radioprogrammen oder Podcasts ein eigener Podcast zusammengestellt werden kann, der relevante Ausschnitte aus einer Vielzahl von Quellen enthält.

Ein möglicher Anwendungsfall wäre eine Person, die sich über das Thema „Überfischung der Meere“ informieren möchte und dafür genau 20 Minuten während einer Autofahrt einplant. 
Das System erstellt nun einen Zusammenschnitt aus verschiedenen Podcast-Episoden zu diesem Thema, der 20 Minuten lang ist, und stellt ihn der Person zur Verfügung. 
Der Vorteil für die Nutzenden liegt darin, dass sie selbst das Thema auswählen und die exakte Länge festlegen können.
Außerdem wird das Thema von verschiedenen Sprechern aus unterschiedlichen Perspektiven erklärt, was zu einer Steigerung der Aufmerksamkeit führt~\cite{kang2012}.

\section{Zielsetzung}

Diese Bachelorarbeit ist in zwei Teile aufgeteilt.
Im ersten Teil der Arbeit wird beschrieben, wie ein Prototyp für ein System zur automatischen Podcastgenerierung aufgebaut sein könnte.
Dazu werden die einzelnen Mikroservices vorgestellt und die Wahl der verwendeten Technologien begründet.
In einigen Fällen werden mehrere unterschiedliche Services miteinander verglichen.
In anderen Fällen wird beschrieben, wie bei der Entstehung des Projektes bestimmte Technologien durch andere ersetzt wurden, da in der Zwischenzeit neue Erkenntnisse gewonnen worden sind.
Für die Auswahl der passenden Audiosegmente werden verschiedene Methoden des Natural Language Processing verwendet, insbesondere Text-Embeddings.
Außerdem werden die Fähigkeiten von Large Language Models genutzt, um die Qualität der generierten Podcast-Episoden zu verbessern.
Für die Interaktion mit dem Benutzer soll außerdem eine grafische Benutzeroberfläche bereitgestellt werden, die den Nutzenden die Auswahl eines Themas und die Länge der Podcast-Episode ermöglicht.

Im zweiten Teil der Arbeit geht es insbesondere um die Auswahl der richtigen Embeddings.
Dabei wird die Fähigkeit, relevante Segmente zu finden, anhand verschiedener Metriken evaluiert.
Es werden die Ausgaben verschiedener Embeddings miteinander verglichen und die Güte mithilfe eines Large Language Models bewertet.

\section{Überblick}

Diese Arbeit ist in acht Kapitel aufgeteilt.

Während im ersten Abschnitt die Zielsetzung, Motivation und ein kurzer Überblick behandelt werden, wird im zweiten Kapitel die verwandte Literatur zusammengefasst.

Im dritten Kapitel werden theoretische Grundlagen zum Verständnis der später aufgeführten Technologien erklärt.

Das vierte Kapitel behandelt die Beschaffung der Audiodaten.
Darin werden verschiedene Methoden zur Transkription dieser Audiodaten beschrieben und begründet, welche Methode der Transkription für diese Arbeit verwendet wird.
Außerdem werden effiziente Wege für die Datenspeicherung diskutiert.

Die Architektur des Systems wird im fünften Kapitel dargestellt.
Dabei wird besonders auf die semantische Analyse der Transkriptionen eingegangen und verschiedene Aspekte des Natural Language Processing sowie der Large Language Modelle vorgestellt.

Im sechsten Kapitel werden verschiedene Methoden zur semantischen Analyse evaluiert.
Dabei werden die verwendeten Modelle, die Wahl der Anzahl und Länge der Abschnitte und die finale Zusammensetzung dieser erklärt und begründet.

Im siebten Kapitel geht es um den Ausblick für zukünftige Weiterentwicklungen.

Das letzte Kapitel fasst die erzielten Ergebnisse zusammen.

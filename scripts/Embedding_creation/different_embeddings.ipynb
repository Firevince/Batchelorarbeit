{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleichen verschiedener Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden die verschiedenen Embedding Algorithmen demonstriert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/br/Projects/Bachelorarbeit/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from db_connect import db_get_df, db_save_df\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Embedding_creation.embedding_creator_TF_IDF import calc_all_tf_idf, calculate_distances\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLAMA 2 Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('mesolitica/llama2-embedding-1b-8k', trust_remote_code = True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('mesolitica/llama2-embedding-1b-8k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df(\"transcript_sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisierung der Sätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\n",
    "    df[\"sentence\"].to_list(), \n",
    "    return_tensors = 'pt',\n",
    "    padding = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model.encode(input_ids).detach().numpy()\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speichern der Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding_json\"] = [json.dumps(model.encode(chunk_text).detach().numpy()) for chunk_text in tqdm(input_ids)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vereinigen der Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = list(\"bcdyefghij\")\n",
    "all_df = db_get_df(\"transcript_segments_llama_2_a\")\n",
    "for id in table_id:\n",
    "    df_temp = db_get_df(f\"transcript_segments_llama_2_{id}\")\n",
    "    # print(len(df_temp))\n",
    "    print(df_temp.head(1).iloc[0, 0])\n",
    "    all_df = pd.concat([all_df, df_temp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_save_df(all_df, \"transcript_segments_llama_2_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = db_get_df(\"transcript_segments_llama_2_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_strings = [json.dumps(row.tolist()) for index, row in all_df.iterrows()]\n",
    "df[\"embedding_json\"] = json_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_save_df(df, \"transcript_segments_llama_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF für alle Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf auf lemmatisierte Sätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df(table=\"sentences_lemmatized\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['sentence_lemmatized'])\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, os.path.join(DATA_PATH,'matricies/tfidf_vectorizer200k.pkl'))\n",
    "print(\"vectorizer file dumped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df(table=\"sentences_lemmatized\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_path = os.path.join(DATA_PATH,'matricies/tf_idf_matrix200k.npz')\n",
    "sparse.save_npz(matrix_path, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_path = os.path.join(DATA_PATH,'matricies/tf_idf_matrix230k.npz')\n",
    "vectorizer_path = os.path.join(DATA_PATH,'matricies/tfidf_vectorizer230k.pkl')\n",
    "tf_idf_matrix = sparse.load_npz(matrix_path)\n",
    "tfidf_vectorizer = joblib.load(vectorizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional speichern des Vocabulars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = dict(sorted(tfidf_vectorizer.get_vocab().items()))\n",
    "output_file = 'vocabulary.txt'\n",
    "with open(output_file, 'w') as file:\n",
    "    for key in sorted_dict.keys():\n",
    "        file.write(key + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_all_tf_idf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.Embedding_creation.embedding_creator_TF_IDF import calc_all_tf_idf, calculate_distances\n",
    "\n",
    "\n",
    "df_tfidf =  calculate_distances(\"Geschichte von Deutschland\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF Analyse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import joblib\n",
    "import spacy\n",
    "\n",
    "tf_idf_matrix = sparse.load_npz(\"tf_idf_matrix.npz\")\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "idf_values = tfidf_vectorizer.idf_\n",
    "idf_dict = dict(zip(feature_names, idf_values))\n",
    "nlp = spacy.load(\"de_core_news_md\")\n",
    "\n",
    "def lemmatize_german_sentence(input_sentence, nlp):\n",
    "    doc = nlp(input_sentence)\n",
    "    lemmatized_words = []\n",
    "    for token in doc:\n",
    "        lemma = token.lemma_\n",
    "        if lemma:\n",
    "            lemmatized_words.append(lemma)\n",
    "        else: \n",
    "            lemmatized_words.append(token)\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df(\"sentences_lemmatized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Wer ist frau meier\"\n",
    "sentence = lemmatize_german_sentence(sentence, nlp)\n",
    "\n",
    "encoded_words = [(idf_dict[word.lower()], word) for word in sentence if word.lower() in idf_dict]\n",
    "print(encoded_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SBert\n",
    "synchron - asynchron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neumannvi84434/Bachelorarbeit/Bachelorarbeit/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from db_connect import db_get_df, db_save_df, save_pkl, load_pkl\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from embedding_creator_MINI_L6 import all_document_embeddings_batchwise_MINI_LM\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/scratch/students/neumannvi84434/data/matrices/test.pkl\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "save_pkl(sentences, embeddings, \"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, embeddings = load_pkl(\"MINI_L6_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370224"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df(table=\"transcript_sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/371 [00:06<39:10,  6.35s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "594",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Bachelorarbeit/Bachelorarbeit/.venv/lib/python3.8/site-packages/pandas/core/indexes/range.py:345\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 594 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mall_document_embeddings_batchwise_MINI_LM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m save_pkl(sentences, embeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMINI_LM.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Bachelorarbeit/Bachelorarbeit/scripts/Embedding_creation/embedding_creator_MINI_L6.py:21\u001b[0m, in \u001b[0;36mall_document_embeddings_batchwise_MINI_LM\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m     19\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(documents), batch_size)):\n\u001b[0;32m---> 21\u001b[0m     batch_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     all_embeddings_list\u001b[38;5;241m.\u001b[39mappend(batch_embedding)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Convert the list of batch embeddings to a 2D NumPy array\u001b[39;00m\n",
      "File \u001b[0;32m~/Bachelorarbeit/Bachelorarbeit/.venv/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:157\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    155\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    156\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_length(sen) \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[0;32m--> 157\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [sentences[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    160\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentences_sorted[start_index:start_index\u001b[38;5;241m+\u001b[39mbatch_size]\n",
      "File \u001b[0;32m~/Bachelorarbeit/Bachelorarbeit/.venv/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:157\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    155\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    156\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_length(sen) \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[0;32m--> 157\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [\u001b[43msentences\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    160\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentences_sorted[start_index:start_index\u001b[38;5;241m+\u001b[39mbatch_size]\n",
      "File \u001b[0;32m~/Bachelorarbeit/Bachelorarbeit/.venv/lib/python3.8/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Bachelorarbeit/Bachelorarbeit/.venv/lib/python3.8/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Bachelorarbeit/Bachelorarbeit/.venv/lib/python3.8/site-packages/pandas/core/indexes/range.py:347\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 594"
     ]
    }
   ],
   "source": [
    "embeddings = all_document_embeddings_batchwise_MINI_LM(df[\"sentence\"])\n",
    "save_pkl(sentences, embeddings, \"MINI_LM.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milvus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from milvus import MilvusServer, debug_server, default_server\n",
    "from pymilvus import (\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    FieldSchema,\n",
    "    connections,\n",
    "    db,\n",
    "    utility,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "DATABASE_PATH = os.getenv(\"DATABASE_PATH\")\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup DB setup und connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_milvius():\n",
    "    debug_server.run()\n",
    "\n",
    "\n",
    "def set_settings():\n",
    "    with default_server:\n",
    "        default_server.set_base_dir(os.path.join(DATA_PATH, \"milvius\"))\n",
    "        default_server.config.set(\"system_Log_level\", \"info\")\n",
    "        default_server.config.set(\"proxy_port\", 19531)\n",
    "        default_server.config.set(\"dataCoord.segment.maxSize\", 1024)\n",
    "\n",
    "def test_server():\n",
    "    default_server.start()\n",
    "    connections.connect(host=\"127.0.0.1\", port=default_server.listen_port)\n",
    "    print(utility.get_server_version())\n",
    "    default_server.stop()\n",
    "\n",
    "\n",
    "def drop_collection(collection):\n",
    "    utility.drop_collection(collection)\n",
    "\n",
    "def create_db():\n",
    "    conn = connections.connect(host=\"127.0.0.1\", port=19530, db_name=\"default\")\n",
    "\n",
    "    database = db.create_database(\"embeddings\")\n",
    "\n",
    "def connect_db():\n",
    "    conn = connections.connect(host=\"127.0.0.1\", port=19530, db_name=\"default\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eine Collection erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection():\n",
    "    filename = FieldSchema(\n",
    "        name=\"filename\",\n",
    "        dtype=DataType.VARCHAR,\n",
    "        max_length=200,\n",
    "        default_value=\"\",\n",
    "        is_primary=True,\n",
    "    )\n",
    "    sentence_id = FieldSchema(\n",
    "        name=\"sentence_id\",\n",
    "        dtype=DataType.INT64,\n",
    "    )\n",
    "    sentence_text = FieldSchema(\n",
    "        name=\"sentence_text\",\n",
    "        dtype=DataType.VARCHAR,\n",
    "        max_length=6000,\n",
    "        default_value=\"\",\n",
    "    )\n",
    "    sentence_mini_lm_embed = FieldSchema(\n",
    "        name=\"sentence_MINI_LM_embed\",\n",
    "        dtype=DataType.FLOAT_VECTOR, \n",
    "        dim=384,\n",
    "        default_value=0,\n",
    "    )\n",
    "    schema = CollectionSchema(\n",
    "        fields=[filename, sentence_id, sentence_text, sentence_mini_lm_embed],\n",
    "        description=\"Setences with MINI_LM Embeddings\",\n",
    "        enable_dynamic_field=True,\n",
    "    )\n",
    "    collection_name = \"sentence_embeddings_MINI_LM\"\n",
    "    collection = Collection(name=collection_name, schema=schema, using=\"default\", shards_num=2)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_collection(\"sentence_embeddings_MINI_LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save MINI_LM in Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from db_connect import db_get_df, db_save_df, save_pkl, load_pkl, save_npz, load_npz\n",
    "from milvus_connect import connect_db\n",
    "from pymilvus import (\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    FieldSchema,\n",
    "    connections,\n",
    "    db,\n",
    "    utility,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_pkl(\"MINI_L6_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df(\"transcript_sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embeddings))\n",
    "print(len(df))\n",
    "print(len(embeddings[0]))\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = Collection(\"sentence_embeddings_MINI_LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_batches(data, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100  \n",
    "start_point = 0\n",
    "\n",
    "filename_batches = list(split_into_batches(df[\"filename\"].tolist(), batch_size))[start_point:]\n",
    "sentence_id_batches = list(split_into_batches(df[\"sentence_id\"].tolist(), batch_size))[start_point:]\n",
    "sentence_text = list(split_into_batches(df[\"sentence_compound_split\"].tolist(), batch_size))[start_point:]\n",
    "embeddings_batches = list(split_into_batches(embeddings.tolist(), batch_size))[start_point:]\n",
    "\n",
    "# Insert each batch into the collection\n",
    "for i in tqdm(range(len(filename_batches))):\n",
    "    batch_data = [\n",
    "        filename_batches[i],\n",
    "        sentence_id_batches[i],\n",
    "        sentence_text[i],\n",
    "        embeddings_batches[i],\n",
    "    ]\n",
    "    insert_result = collection.insert(batch_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = {\n",
    "  \"metric_type\":\"L2\",\n",
    "  \"index_type\":\"IVF_FLAT\",\n",
    "  \"params\":{\"nlist\":1024}\n",
    "}\n",
    "collection.create_index(\n",
    "  field_name=\"sentence_MINI_LM_embed\", \n",
    "  index_params=index_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collection.schema)                # Return the schema.CollectionSchema of the collection.\n",
    "print(collection.description      )     # Return the description of the collection.\n",
    "print(collection.name            )      # Return the name of the collection.\n",
    "print(collection.is_empty       )       # Return the boolean value that indicates if the collection is empty.\n",
    "print(collection.num_entities  )        # Return the number of entities in the collection.\n",
    "print(collection.primary_field)         # Return the schema.FieldSchema of the primary key field.\n",
    "print(collection.partitions  )          # Return the list[Partition] object.\n",
    "print(collection.indexes    )           # Return the list[Index] object.\n",
    "# print(collection.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from embedding_creation.embedding_creator_MINI_L6 import document_embedding_MINI_LM\n",
    "from db_connect import db_get_df, db_save_df, save_pkl, load_pkl, save_npz, load_npz\n",
    "from milvus_connect import connect_db\n",
    "from pymilvus import Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_db()\n",
    "collection = Collection(\"sentence_embeddings_MINI_LM\")\n",
    "search_params = {\n",
    "    \"metric_type\": \"L2\", \n",
    "    \"offset\": 0, \n",
    "    \"ignore_growing\": False, \n",
    "    \"params\": {\"nprobe\": 10}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Kangal\"\n",
    "question_embedding = document_embedding_MINI_LM(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.search(\n",
    "    data=question_embedding, \n",
    "    anns_field=\"sentence_MINI_LM_embed\", \n",
    "    param=search_params,\n",
    "    limit=10,\n",
    "    expr=None,\n",
    "    output_fields=['sentence_text'],\n",
    "    consistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save tf_idf in collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from db_connect import db_get_df, db_save_df, save_pkl, load_pkl, save_npz, load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertrizer = load_pkl(\"tfidf_vectorizer_compound_split_87k.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vertrizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_get_df(\"transcript_sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    df[\"sentence_id\"].tolist(),\n",
    "    df[\"filename\"].tolist(),\n",
    "    df[\"sentence_compound_split\"].tolist(),\n",
    "    df[\"sentence_tf_idf_embed\"].tolist(),\n",
    "]\n",
    "\n",
    "# Insert the data into the collection\n",
    "insert_result = collection.insert(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vectors = df['vectors'].to_list()\n",
    "\n",
    "mr = collection.insert([vectors])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

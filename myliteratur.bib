@article{barthel,
  title = {Measuring {{News Consumption}} in a {{Digital Era}}},
  author = {Barthel, Michael and Mitchell, Amy and Asare-Marfo, Dorene and Kennedy, Courtney},
  langid = {english},
  keywords = {noch nicht gelesen},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Barthel et al.pdf}
}

@online{choi2018,
  title = {{{QuAC}} : {{Question Answering}} in {{Context}}},
  shorttitle = {{{QuAC}}},
  author = {Choi, Eunsol and He, He and Iyyer, Mohit and Yatskar, Mark and Yih, Wen-tau and Choi, Yejin and Liang, Percy and Zettlemoyer, Luke},
  date = {2018-08-27},
  eprint = {1808.07036},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1808.07036},
  urldate = {2023-11-08},
  abstract = {We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-of-the-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at http://quac.ai.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Choi et al2018.pdf;/Users/br/Zotero/storage/7Y37KALC/1808.html}
}

@online{clark2020,
  title = {{{ELECTRA}}: {{Pre-training Text Encoders}} as {{Discriminators Rather Than Generators}}},
  shorttitle = {{{ELECTRA}}},
  author = {Clark, Kevin and Luong, Minh-Thang and Le, Quoc V. and Manning, Christopher D.},
  date = {2020-03-23},
  eprint = {2003.10555},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2003.10555},
  urldate = {2023-11-08},
  abstract = {Masked language modeling (MLM) pre-training methods such as BERT corrupt the input by replacing some tokens with [MASK] and then train a model to reconstruct the original tokens. While they produce good results when transferred to downstream NLP tasks, they generally require large amounts of compute to be effective. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the task is defined over all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by BERT given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where it performs comparably to RoBERTa and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Clark et al2020.pdf;/Users/br/Zotero/storage/KQEAMJR3/2003.html}
}

@online{du2017,
  title = {Learning to {{Ask}}: {{Neural Question Generation}} for {{Reading Comprehension}}},
  shorttitle = {Learning to {{Ask}}},
  author = {Du, Xinya and Shao, Junru and Cardie, Claire},
  date = {2017-04-28},
  eprint = {1705.00106},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1705.00106},
  urldate = {2023-11-08},
  abstract = {We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our system significantly outperforms the state-of-the-art rule-based system. In human evaluations, questions generated by our system are also rated as being more natural (i.e., grammaticality, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer).},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Du et al2017.pdf;/Users/br/Zotero/storage/N4IELHG4/1705.html}
}

@online{jones2021,
  title = {{{TREC}} 2020 {{Podcasts Track Overview}}},
  author = {Jones, Rosie and Carterette, Ben and Clifton, Ann and Eskevich, Maria and Jones, Gareth J. F. and Karlgren, Jussi and Pappu, Aasish and Reddy, Sravana and Yu, Yongze},
  date = {2021-03-29},
  eprint = {2103.15953},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.15953},
  url = {http://arxiv.org/abs/2103.15953},
  urldate = {2023-11-06},
  abstract = {The Podcast Track is new at the Text Retrieval Conference (TREC) in 2020. The podcast track was designed to encourage research into podcasts in the information retrieval and NLP research communities. The track consisted of two shared tasks: segment retrieval and summarization, both based on a dataset of over 100,000 podcast episodes (metadata, audio, and automatic transcripts) which was released concurrently with the track. The track generated considerable interest, attracted hundreds of new registrations to TREC and fifteen teams, mostly disjoint between search and summarization, made final submissions for assessment. Deep learning was the dominant experimental approach for both search experiments and summarization. This paper gives an overview of the tasks and the results of the participants' experiments. The track will return to TREC 2021 with the same two tasks, incorporating slight modifications in response to participant feedback.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,noch nicht gelesen},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Jones et al2021.pdf;/Users/br/Zotero/storage/339BCE5J/2103.html}
}

@article{kang2012,
  title = {Effects of Podcast Tours on Tourist Experiences in a National Park},
  author = {Kang, Myunghwa and Gretzel, Ulrike},
  date = {2012-04},
  journaltitle = {Tourism Management},
  shortjournal = {Tourism Management},
  volume = {33},
  number = {2},
  pages = {440--455},
  issn = {02615177},
  doi = {10.1016/j.tourman.2011.05.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0261517711001075},
  urldate = {2023-11-08},
  abstract = {This study examines the influence of podcast tours on tourist experiences. Based on theoretical accounts that human voices convey rich social information, this study proposes that podcast tours increase perceived social presence and mindfulness that lead to enhanced tourist experiences and environmental stewardship. A field experiment was conducted at a national park using MP3 players containing podcast tours based on four experimental conditions: 2 information source compositions (single vs. multiple narrator voices) Â 2 narrating styles (formal vs. conversational). The results support that even if communicated through audio-only media, the human voice creates a positive social context for meaningful interaction which influences tourist experiences and stewardship. Mindfulness was also found to be an important construct affecting the quality of experiences. The findings support the usefulness of podcast tours as interpretative media.},
  langid = {english},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Kang_Gretzel2012.pdf}
}

@online{karpukhin2020,
  title = {Dense {{Passage Retrieval}} for {{Open-Domain Question Answering}}},
  author = {Karpukhin, Vladimir and Oğuz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  date = {2020-09-30},
  eprint = {2004.04906},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2004.04906},
  urldate = {2023-11-08},
  abstract = {Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9\%-19\% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Karpukhin et al2020.pdf;/Users/br/Zotero/storage/62QDY3FJ/2004.html}
}

@inproceedings{laban2022,
  title = {{{NewsPod}}: {{Automatic}} and {{Interactive News Podcasts}}},
  shorttitle = {{{NewsPod}}},
  booktitle = {27th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Laban, Philippe and Ye, Elicia and Korlakunta, Srujay and Canny, John and Hearst, Marti},
  date = {2022-03-22},
  pages = {691--706},
  publisher = {{ACM}},
  location = {{Helsinki Finland}},
  doi = {10.1145/3490099.3511147},
  url = {https://dl.acm.org/doi/10.1145/3490099.3511147},
  urldate = {2023-11-06},
  eventtitle = {{{IUI}} '22: 27th {{International Conference}} on {{Intelligent User Interfaces}}},
  isbn = {978-1-4503-9144-3},
  langid = {english},
  keywords = {Gelesen,Obsidian Notes},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Laban et al2022.pdf}
}

@inproceedings{lochrie2018,
  title = {Designing {{Immersive Audio Experiences}} for {{News}} and {{Information}} in the {{Internet}} of {{Things}} Using {{Text-to-Speech Objects}}},
  author = {Lochrie, Mark and De-Neef, Robin and Mills, John and Davenport, Jack},
  date = {2018},
  doi = {10.14236/ewic/HCI2018.90},
  url = {https://scienceopen.com/hosted-document?doi=10.14236/ewic/HCI2018.90},
  urldate = {2023-11-08},
  eventtitle = {Proceedings of the 32nd {{International BCS Human Computer Interaction Conference}}},
  langid = {english},
  keywords = {noch nicht gelesen},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Lochrie et al2018.pdf}
}

@article{maroni2020,
  title = {KÜNSTLICHE INTELLIGENZ IM PRODUKTIVEN EINSATZ FÜR DIE AUTOMATISIERTE ERSCHLIESSUNG IM MULTIMEDIALEN PRODUKTIONSPROZESS},
  author = {Maroni, Dirk and Köhler, Joachim and Fisseler, Jens and Becker, Sven},
  date = {2020},
  langid = {ngerman},
  keywords = {noch nicht gelesen},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Maroni et al2020.pdf}
}

@inproceedings{moldovan2000,
  title = {The {{Structure}} and {{Performance}} of an {{Open-Domain Question Answering System}}},
  booktitle = {Proceedings of the 38th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Moldovan, Dan and Harabagiu, Sanda and Pasca, Marius and Mihalcea, Rada and Girju, Roxana and Goodrum, Richard and Rus, Vasile},
  date = {2000-10},
  pages = {563--570},
  publisher = {{Association for Computational Linguistics}},
  location = {{Hong Kong}},
  doi = {10.3115/1075218.1075289},
  url = {https://aclanthology.org/P00-1071},
  urldate = {2023-11-08},
  eventtitle = {{{ACL}} 2000},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Moldovan et al2000.pdf}
}

@online{oord2016,
  title = {{{WaveNet}}: {{A Generative Model}} for {{Raw Audio}}},
  shorttitle = {{{WaveNet}}},
  author = {family=Oord, given=Aaron, prefix=van den, useprefix=false and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  date = {2016-09-19},
  eprint = {1609.03499},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1609.03499},
  urldate = {2023-11-08},
  abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-ofthe-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,noch nicht gelesen},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Oord et al2016.pdf}
}

@article{reddy2019,
  title = {{{CoQA}}: {{A Conversational Question Answering Challenge}}},
  shorttitle = {{{CoQA}}},
  author = {Reddy, Siva and Chen, Danqi and Manning, Christopher D.},
  date = {2019-11},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  shortjournal = {Transactions of the Association for Computational Linguistics},
  volume = {7},
  pages = {249--266},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00266},
  url = {https://direct.mit.edu/tacl/article/43511},
  urldate = {2023-11-08},
  abstract = {Humans gather information through conversations involving a series of interconnected questions and answers. For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions. We introduce CoQA, a novel dataset for building Conversational Question Answering systems. Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains. The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage. We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets (e.g., coreference and pragmatic reasoning). We evaluate strong dialogue and reading comprehension models on CoQA. The best system obtains an F1 score of 65.4\%, which is 23.4 points behind human performance (88.8\%), indicating that there is ample room for improvement. We present CoQA as a challenge to the community at https://stanfordnlp.github. io/coqa.},
  langid = {english},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Reddy et al2019.pdf}
}

@inproceedings{sahijwani2020,
  title = {Would {{You Like}} to {{Hear}} the {{News}}?: {{Investigating Voice-Based Suggestions}} for {{Conversational News Recommendation}}},
  shorttitle = {Would {{You Like}} to {{Hear}} the {{News}}?},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Human Information Interaction}} and {{Retrieval}}},
  author = {Sahijwani, Harshita and Choi, Jason Ingyu and Agichtein, Eugene},
  date = {2020-03-14},
  pages = {437--441},
  publisher = {{ACM}},
  location = {{Vancouver BC Canada}},
  doi = {10.1145/3343413.3378013},
  url = {https://dl.acm.org/doi/10.1145/3343413.3378013},
  urldate = {2023-11-08},
  abstract = {One of the key benefits of voice-based personal assistants is the potential to proactively recommend relevant and interesting information. One of the most valuable sources of such information is the News. However, in order for the user to hear the news that is useful and relevant to them, it must be recommended in an interesting and informative way. However, to the best of our knowledge, how to present a news item for a voice-based recommendation remains an open question. In this paper, we empirically compare different ways of recommending news, or specific news items, in a voice-based conversational setting. Specifically, we study the user engagement and satisfaction with five different variants of presenting news recommendations: (1) a generic news briefing; (2) news about a specific entity relevant to the current conversation; (3) news about an entity from a past conversation; (4) news on a trending news topic; and (5) the default - a suggestion to talk about news in general. Our results show that entity-based news recommendations exhibit 29\% higher acceptance compared to briefing recommendations, and almost 100\% higher acceptance compared to recommending generic or trending news. Our investigation into the presentation of news recommendations and the resulting insights could make voice assistants more informative and engaging.},
  eventtitle = {{{CHIIR}} '20: {{Conference}} on {{Human Information Interaction}} and {{Retrieval}}},
  isbn = {978-1-4503-6892-6},
  langid = {english},
  keywords = {noch nicht gelesen},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Sahijwani et al2020.pdf}
}

@inproceedings{zhang2020,
  title = {{{PEGASUS}}},
  shorttitle = {{{PEGASUS}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter},
  date = {2020-11-21},
  pages = {11328--11339},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/zhang20ae.html},
  urldate = {2023-11-08},
  abstract = {Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization. However, pre-training objectives tailored for abstractive text summarization have not been explored. Furthermore there is a lack of systematic evaluation across diverse domains. In this work, we propose pre-training large Transformer-based encoder-decoder models on massive text corpora with a new self-supervised objective. In PEGASUS, important sentences are removed/masked from an input document and are generated together as one output sequence from the remaining sentences, similar to an extractive summary. We evaluated our best PEGASUS model on 12 downstream summarization tasks spanning news, science, stories, instructions, emails, patents, and legislative bills. Experiments demonstrate it achieves state-of-the-art performance on all 12 downstream datasets measured by ROUGE scores. Our model also shows surprising performance on low-resource summarization, surpassing previous state-of-the-art results on 6 datasets with only 1000 examples. Finally we validated our results using human evaluation and show that our model summaries achieve human performance on multiple datasets.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/br/Documents/Vincent' Vault/PDFs/Zhang et al2020.pdf}
}
